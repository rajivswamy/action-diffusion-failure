{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/home/woodbury/rajiv/action-diffusion-failure/notebooks\n"
          ]
        }
      ],
      "source": [
        "# get the working directory of the notebook\n",
        "!pwd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67,
          "referenced_widgets": [
            "a8e97e26d65147efa2ddb176214e818a",
            "19e913a07b044b2d91ca7b5d2dbbe8f7",
            "1de97479fc3e44caae336cf0b1082d02",
            "b8d4e152c232416f82f5fb30e2478ef8",
            "d66b3f8971b24c81abaefe111e6383a6",
            "11d14b9bf0f74bf7bd1b58e6a26fd49e",
            "e9fde27bd58b499bb386b36314d9efca",
            "5407db80343c44c79350021cd98204f8",
            "68e9f5994766480dac5dc77ce043a2e9",
            "d00c195ac5644bd0aba81dccf56e2df0",
            "54c35b52c4e24543872c8335c935c410"
          ]
        },
        "id": "VrX4VTl5pYNq",
        "outputId": "63f38652-f298-4723-bd5c-e1bbe5f9d961"
      },
      "outputs": [],
      "source": [
        "#@markdown ### **Imports**\n",
        "# diffusion policy import\n",
        "from typing import Tuple, Sequence, Dict, Union, Optional, Callable\n",
        "import numpy as np\n",
        "import math\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision\n",
        "import collections\n",
        "import zarr\n",
        "from diffusers.schedulers.scheduling_ddpm import DDPMScheduler\n",
        "from diffusers.training_utils import EMAModel\n",
        "from diffusers.optimization import get_scheduler\n",
        "from tqdm import tqdm\n",
        "\n",
        "# env import\n",
        "import gym\n",
        "from gym import spaces\n",
        "import pygame\n",
        "import pymunk\n",
        "import pymunk.pygame_util\n",
        "from pymunk.space_debug_draw_options import SpaceDebugColor\n",
        "from pymunk.vec2d import Vec2d\n",
        "import shapely.geometry as sg\n",
        "import cv2\n",
        "import skimage.transform as st\n",
        "from skvideo.io import vwrite\n",
        "from IPython.display import Video\n",
        "import gdown\n",
        "import os"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "L5E-nR6ornyg"
      },
      "outputs": [],
      "source": [
        "#@markdown ### **Environment**\n",
        "#@markdown Defines a PyMunk-based Push-T environment `PushTEnv`.\n",
        "#@markdown And it's subclass `PushTImageEnv`.\n",
        "#@markdown\n",
        "#@markdown **Goal**: push the gray T-block into the green area.\n",
        "#@markdown\n",
        "#@markdown Adapted from [Implicit Behavior Cloning](https://implicitbc.github.io/)\n",
        "\n",
        "\n",
        "positive_y_is_up: bool = False\n",
        "\"\"\"Make increasing values of y point upwards.\n",
        "\n",
        "When True::\n",
        "\n",
        "    y\n",
        "    ^\n",
        "    |      . (3, 3)\n",
        "    |\n",
        "    |   . (2, 2)\n",
        "    |\n",
        "    +------ > x\n",
        "\n",
        "When False::\n",
        "\n",
        "    +------ > x\n",
        "    |\n",
        "    |   . (2, 2)\n",
        "    |\n",
        "    |      . (3, 3)\n",
        "    v\n",
        "    y\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "def to_pygame(p: Tuple[float, float], surface: pygame.Surface) -> Tuple[int, int]:\n",
        "    \"\"\"Convenience method to convert pymunk coordinates to pygame surface\n",
        "    local coordinates.\n",
        "\n",
        "    Note that in case positive_y_is_up is False, this function wont actually do\n",
        "    anything except converting the point to integers.\n",
        "    \"\"\"\n",
        "    if positive_y_is_up:\n",
        "        return round(p[0]), surface.get_height() - round(p[1])\n",
        "    else:\n",
        "        return round(p[0]), round(p[1])\n",
        "\n",
        "\n",
        "def light_color(color: SpaceDebugColor):\n",
        "    color = np.minimum(1.2 * np.float32([color.r, color.g, color.b, color.a]), np.float32([255]))\n",
        "    color = SpaceDebugColor(r=color[0], g=color[1], b=color[2], a=color[3])\n",
        "    return color\n",
        "\n",
        "class DrawOptions(pymunk.SpaceDebugDrawOptions):\n",
        "    def __init__(self, surface: pygame.Surface) -> None:\n",
        "        \"\"\"Draw a pymunk.Space on a pygame.Surface object.\n",
        "\n",
        "        Typical usage::\n",
        "\n",
        "        >>> import pymunk\n",
        "        >>> surface = pygame.Surface((10,10))\n",
        "        >>> space = pymunk.Space()\n",
        "        >>> options = pymunk.pygame_util.DrawOptions(surface)\n",
        "        >>> space.debug_draw(options)\n",
        "\n",
        "        You can control the color of a shape by setting shape.color to the color\n",
        "        you want it drawn in::\n",
        "\n",
        "        >>> c = pymunk.Circle(None, 10)\n",
        "        >>> c.color = pygame.Color(\"pink\")\n",
        "\n",
        "        See pygame_util.demo.py for a full example\n",
        "\n",
        "        Since pygame uses a coordiante system where y points down (in contrast\n",
        "        to many other cases), you either have to make the physics simulation\n",
        "        with Pymunk also behave in that way, or flip everything when you draw.\n",
        "\n",
        "        The easiest is probably to just make the simulation behave the same\n",
        "        way as Pygame does. In that way all coordinates used are in the same\n",
        "        orientation and easy to reason about::\n",
        "\n",
        "        >>> space = pymunk.Space()\n",
        "        >>> space.gravity = (0, -1000)\n",
        "        >>> body = pymunk.Body()\n",
        "        >>> body.position = (0, 0) # will be positioned in the top left corner\n",
        "        >>> space.debug_draw(options)\n",
        "\n",
        "        To flip the drawing its possible to set the module property\n",
        "        :py:data:`positive_y_is_up` to True. Then the pygame drawing will flip\n",
        "        the simulation upside down before drawing::\n",
        "\n",
        "        >>> positive_y_is_up = True\n",
        "        >>> body = pymunk.Body()\n",
        "        >>> body.position = (0, 0)\n",
        "        >>> # Body will be position in bottom left corner\n",
        "\n",
        "        :Parameters:\n",
        "                surface : pygame.Surface\n",
        "                    Surface that the objects will be drawn on\n",
        "        \"\"\"\n",
        "        self.surface = surface\n",
        "        super(DrawOptions, self).__init__()\n",
        "\n",
        "    def draw_circle(\n",
        "        self,\n",
        "        pos: Vec2d,\n",
        "        angle: float,\n",
        "        radius: float,\n",
        "        outline_color: SpaceDebugColor,\n",
        "        fill_color: SpaceDebugColor,\n",
        "    ) -> None:\n",
        "        p = to_pygame(pos, self.surface)\n",
        "\n",
        "        pygame.draw.circle(self.surface, fill_color.as_int(), p, round(radius), 0)\n",
        "        pygame.draw.circle(self.surface, light_color(fill_color).as_int(), p, round(radius-4), 0)\n",
        "\n",
        "        circle_edge = pos + Vec2d(radius, 0).rotated(angle)\n",
        "        p2 = to_pygame(circle_edge, self.surface)\n",
        "        line_r = 2 if radius > 20 else 1\n",
        "        # pygame.draw.lines(self.surface, outline_color.as_int(), False, [p, p2], line_r)\n",
        "\n",
        "    def draw_segment(self, a: Vec2d, b: Vec2d, color: SpaceDebugColor) -> None:\n",
        "        p1 = to_pygame(a, self.surface)\n",
        "        p2 = to_pygame(b, self.surface)\n",
        "\n",
        "        pygame.draw.aalines(self.surface, color.as_int(), False, [p1, p2])\n",
        "\n",
        "    def draw_fat_segment(\n",
        "        self,\n",
        "        a: Tuple[float, float],\n",
        "        b: Tuple[float, float],\n",
        "        radius: float,\n",
        "        outline_color: SpaceDebugColor,\n",
        "        fill_color: SpaceDebugColor,\n",
        "    ) -> None:\n",
        "        p1 = to_pygame(a, self.surface)\n",
        "        p2 = to_pygame(b, self.surface)\n",
        "\n",
        "        r = round(max(1, radius * 2))\n",
        "        pygame.draw.lines(self.surface, fill_color.as_int(), False, [p1, p2], r)\n",
        "        if r > 2:\n",
        "            orthog = [abs(p2[1] - p1[1]), abs(p2[0] - p1[0])]\n",
        "            if orthog[0] == 0 and orthog[1] == 0:\n",
        "                return\n",
        "            scale = radius / (orthog[0] * orthog[0] + orthog[1] * orthog[1]) ** 0.5\n",
        "            orthog[0] = round(orthog[0] * scale)\n",
        "            orthog[1] = round(orthog[1] * scale)\n",
        "            points = [\n",
        "                (p1[0] - orthog[0], p1[1] - orthog[1]),\n",
        "                (p1[0] + orthog[0], p1[1] + orthog[1]),\n",
        "                (p2[0] + orthog[0], p2[1] + orthog[1]),\n",
        "                (p2[0] - orthog[0], p2[1] - orthog[1]),\n",
        "            ]\n",
        "            pygame.draw.polygon(self.surface, fill_color.as_int(), points)\n",
        "            pygame.draw.circle(\n",
        "                self.surface,\n",
        "                fill_color.as_int(),\n",
        "                (round(p1[0]), round(p1[1])),\n",
        "                round(radius),\n",
        "            )\n",
        "            pygame.draw.circle(\n",
        "                self.surface,\n",
        "                fill_color.as_int(),\n",
        "                (round(p2[0]), round(p2[1])),\n",
        "                round(radius),\n",
        "            )\n",
        "\n",
        "    def draw_polygon(\n",
        "        self,\n",
        "        verts: Sequence[Tuple[float, float]],\n",
        "        radius: float,\n",
        "        outline_color: SpaceDebugColor,\n",
        "        fill_color: SpaceDebugColor,\n",
        "    ) -> None:\n",
        "        ps = [to_pygame(v, self.surface) for v in verts]\n",
        "        ps += [ps[0]]\n",
        "\n",
        "        radius = 2\n",
        "        pygame.draw.polygon(self.surface, light_color(fill_color).as_int(), ps)\n",
        "\n",
        "        if radius > 0:\n",
        "            for i in range(len(verts)):\n",
        "                a = verts[i]\n",
        "                b = verts[(i + 1) % len(verts)]\n",
        "                self.draw_fat_segment(a, b, radius, fill_color, fill_color)\n",
        "\n",
        "    def draw_dot(\n",
        "        self, size: float, pos: Tuple[float, float], color: SpaceDebugColor\n",
        "    ) -> None:\n",
        "        p = to_pygame(pos, self.surface)\n",
        "        pygame.draw.circle(self.surface, color.as_int(), p, round(size), 0)\n",
        "\n",
        "\n",
        "def pymunk_to_shapely(body, shapes):\n",
        "    geoms = list()\n",
        "    for shape in shapes:\n",
        "        if isinstance(shape, pymunk.shapes.Poly):\n",
        "            verts = [body.local_to_world(v) for v in shape.get_vertices()]\n",
        "            verts += [verts[0]]\n",
        "            geoms.append(sg.Polygon(verts))\n",
        "        else:\n",
        "            raise RuntimeError(f'Unsupported shape type {type(shape)}')\n",
        "    geom = sg.MultiPolygon(geoms)\n",
        "    return geom\n",
        "\n",
        "# env\n",
        "class PushTEnv(gym.Env):\n",
        "    metadata = {\"render.modes\": [\"human\", \"rgb_array\"], \"video.frames_per_second\": 10}\n",
        "    reward_range = (0., 1.)\n",
        "\n",
        "    def __init__(self,\n",
        "            legacy=False,\n",
        "            block_cog=None, \n",
        "            damping=None,\n",
        "            render_action=True,\n",
        "            render_size=96,\n",
        "            reset_to_state=None\n",
        "        ):\n",
        "        self._seed = None\n",
        "        self.seed()\n",
        "        self.window_size = ws = 512  # The size of the PyGame window\n",
        "        self.render_size = render_size\n",
        "        self.sim_hz = 100\n",
        "        # Local controller params.\n",
        "        self.k_p, self.k_v = 100, 20    # PD control.z\n",
        "        self.control_hz = self.metadata['video.frames_per_second']\n",
        "        # legcay set_state for data compatiblity\n",
        "        self.legacy = legacy\n",
        "\n",
        "        # agent_pos, block_pos, block_angle\n",
        "        self.observation_space = spaces.Box(\n",
        "            low=np.array([0,0,0,0,0], dtype=np.float64),\n",
        "            high=np.array([ws,ws,ws,ws,np.pi*2], dtype=np.float64),\n",
        "            shape=(5,),\n",
        "            dtype=np.float64\n",
        "        )\n",
        "\n",
        "        # positional goal for agent\n",
        "        self.action_space = spaces.Box(\n",
        "            low=np.array([0,0], dtype=np.float64),\n",
        "            high=np.array([ws,ws], dtype=np.float64),\n",
        "            shape=(2,),\n",
        "            dtype=np.float64\n",
        "        )\n",
        "\n",
        "        self.block_cog = block_cog\n",
        "        self.damping = damping\n",
        "        self.render_action = render_action\n",
        "\n",
        "        \"\"\"\n",
        "        If human-rendering is used, `self.window` will be a reference\n",
        "        to the window that we draw to. `self.clock` will be a clock that is used\n",
        "        to ensure that the environment is rendered at the correct framerate in\n",
        "        human-mode. They will remain `None` until human-mode is used for the\n",
        "        first time.\n",
        "        \"\"\"\n",
        "        self.window = None\n",
        "        self.clock = None\n",
        "        self.screen = None\n",
        "\n",
        "        self.space = None\n",
        "        self.teleop = None\n",
        "        self.render_buffer = None\n",
        "        self.latest_action = None\n",
        "        self.reset_to_state = reset_to_state\n",
        "\n",
        "    def reset(self):\n",
        "        seed = self._seed\n",
        "        self._setup()\n",
        "        if self.block_cog is not None:\n",
        "            self.block.center_of_gravity = self.block_cog\n",
        "        if self.damping is not None:\n",
        "            self.space.damping = self.damping\n",
        "\n",
        "        # use legacy RandomState for compatiblity\n",
        "        state = self.reset_to_state\n",
        "        if state is None:\n",
        "            rs = np.random.RandomState(seed=seed)\n",
        "            state = np.array([\n",
        "                rs.randint(50, 450), rs.randint(50, 450),\n",
        "                rs.randint(100, 400), rs.randint(100, 400),\n",
        "                rs.randn() * 2 * np.pi - np.pi\n",
        "                ])\n",
        "        self._set_state(state)\n",
        "\n",
        "        obs = self._get_obs()\n",
        "        info = self._get_info()\n",
        "        return obs, info\n",
        "\n",
        "    def step(self, action):\n",
        "        dt = 1.0 / self.sim_hz\n",
        "        self.n_contact_points = 0\n",
        "        n_steps = self.sim_hz // self.control_hz\n",
        "        if action is not None:\n",
        "            self.latest_action = action\n",
        "            for i in range(n_steps):\n",
        "                # Step PD control.\n",
        "                # self.agent.velocity = self.k_p * (act - self.agent.position)    # P control works too.\n",
        "                acceleration = self.k_p * (action - self.agent.position) + self.k_v * (Vec2d(0, 0) - self.agent.velocity)\n",
        "                self.agent.velocity += acceleration * dt\n",
        "\n",
        "                # Step physics.\n",
        "                self.space.step(dt)\n",
        "\n",
        "        # compute reward\n",
        "        goal_body = self._get_goal_pose_body(self.goal_pose)\n",
        "        goal_geom = pymunk_to_shapely(goal_body, self.block.shapes)\n",
        "        block_geom = pymunk_to_shapely(self.block, self.block.shapes)\n",
        "\n",
        "        intersection_area = goal_geom.intersection(block_geom).area\n",
        "        goal_area = goal_geom.area\n",
        "        coverage = intersection_area / goal_area\n",
        "        reward = np.clip(coverage / self.success_threshold, 0, 1)\n",
        "        done = coverage > self.success_threshold\n",
        "        terminated = done\n",
        "        truncated = done\n",
        "\n",
        "        observation = self._get_obs()\n",
        "        info = self._get_info()\n",
        "\n",
        "        return observation, reward, terminated, truncated, info\n",
        "\n",
        "    def render(self, mode):\n",
        "        return self._render_frame(mode)\n",
        "\n",
        "    def teleop_agent(self):\n",
        "        TeleopAgent = collections.namedtuple('TeleopAgent', ['act'])\n",
        "        def act(obs):\n",
        "            act = None\n",
        "            mouse_position = pymunk.pygame_util.from_pygame(Vec2d(*pygame.mouse.get_pos()), self.screen)\n",
        "            if self.teleop or (mouse_position - self.agent.position).length < 30:\n",
        "                self.teleop = True\n",
        "                act = mouse_position\n",
        "            return act\n",
        "        return TeleopAgent(act)\n",
        "\n",
        "    def _get_obs(self):\n",
        "        obs = np.array(\n",
        "            tuple(self.agent.position) \\\n",
        "            + tuple(self.block.position) \\\n",
        "            + (self.block.angle % (2 * np.pi),))\n",
        "        return obs\n",
        "\n",
        "    def _get_goal_pose_body(self, pose):\n",
        "        mass = 1\n",
        "        inertia = pymunk.moment_for_box(mass, (50, 100))\n",
        "        body = pymunk.Body(mass, inertia)\n",
        "        # preserving the legacy assignment order for compatibility\n",
        "        # the order here dosn't matter somehow, maybe because CoM is aligned with body origin\n",
        "        body.position = pose[:2].tolist()\n",
        "        body.angle = pose[2]\n",
        "        return body\n",
        "\n",
        "    def _get_info(self):\n",
        "        n_steps = self.sim_hz // self.control_hz\n",
        "        n_contact_points_per_step = int(np.ceil(self.n_contact_points / n_steps))\n",
        "        info = {\n",
        "            'pos_agent': np.array(self.agent.position),\n",
        "            'vel_agent': np.array(self.agent.velocity),\n",
        "            'block_pose': np.array(list(self.block.position) + [self.block.angle]),\n",
        "            'goal_pose': self.goal_pose,\n",
        "            'n_contacts': n_contact_points_per_step}\n",
        "        return info\n",
        "\n",
        "    def _render_frame(self, mode):\n",
        "\n",
        "        if self.window is None and mode == \"human\":\n",
        "            pygame.init()\n",
        "            pygame.display.init()\n",
        "            self.window = pygame.display.set_mode((self.window_size, self.window_size))\n",
        "        if self.clock is None and mode == \"human\":\n",
        "            self.clock = pygame.time.Clock()\n",
        "\n",
        "        canvas = pygame.Surface((self.window_size, self.window_size))\n",
        "        canvas.fill((255, 255, 255))\n",
        "        self.screen = canvas\n",
        "\n",
        "        draw_options = DrawOptions(canvas)\n",
        "\n",
        "        # Draw goal pose.\n",
        "        goal_body = self._get_goal_pose_body(self.goal_pose)\n",
        "        for shape in self.block.shapes:\n",
        "            goal_points = [pymunk.pygame_util.to_pygame(goal_body.local_to_world(v), draw_options.surface) for v in shape.get_vertices()]\n",
        "            goal_points += [goal_points[0]]\n",
        "            pygame.draw.polygon(canvas, self.goal_color, goal_points)\n",
        "\n",
        "        # Draw agent and block.\n",
        "        self.space.debug_draw(draw_options)\n",
        "\n",
        "        if mode == \"human\":\n",
        "            # The following line copies our drawings from `canvas` to the visible window\n",
        "            self.window.blit(canvas, canvas.get_rect())\n",
        "            pygame.event.pump()\n",
        "            pygame.display.update()\n",
        "\n",
        "            # the clock is aleady ticked during in step for \"human\"\n",
        "\n",
        "\n",
        "        img = np.transpose(\n",
        "                np.array(pygame.surfarray.pixels3d(canvas)), axes=(1, 0, 2)\n",
        "            )\n",
        "        img = cv2.resize(img, (self.render_size, self.render_size))\n",
        "        if self.render_action:\n",
        "            if self.render_action and (self.latest_action is not None):\n",
        "                action = np.array(self.latest_action)\n",
        "                coord = (action / 512 * 96).astype(np.int32)\n",
        "                marker_size = int(8/96*self.render_size)\n",
        "                thickness = int(1/96*self.render_size)\n",
        "                cv2.drawMarker(img, coord,\n",
        "                    color=(255,0,0), markerType=cv2.MARKER_CROSS,\n",
        "                    markerSize=marker_size, thickness=thickness)\n",
        "        return img\n",
        "\n",
        "\n",
        "    def close(self):\n",
        "        if self.window is not None:\n",
        "            pygame.display.quit()\n",
        "            pygame.quit()\n",
        "\n",
        "    def seed(self, seed=None):\n",
        "        if seed is None:\n",
        "            seed = np.random.randint(0,25536)\n",
        "        self._seed = seed\n",
        "        self.np_random = np.random.default_rng(seed)\n",
        "\n",
        "    def _handle_collision(self, arbiter, space, data):\n",
        "        self.n_contact_points += len(arbiter.contact_point_set.points)\n",
        "\n",
        "    def _set_state(self, state):\n",
        "        if isinstance(state, np.ndarray):\n",
        "            state = state.tolist()\n",
        "        pos_agent = state[:2]\n",
        "        pos_block = state[2:4]\n",
        "        rot_block = state[4]\n",
        "        self.agent.position = pos_agent\n",
        "        # setting angle rotates with respect to center of mass\n",
        "        # therefore will modify the geometric position\n",
        "        # if not the same as CoM\n",
        "        # therefore should be modified first.\n",
        "        if self.legacy:\n",
        "            # for compatiblity with legacy data\n",
        "            self.block.position = pos_block\n",
        "            self.block.angle = rot_block\n",
        "        else:\n",
        "            self.block.angle = rot_block\n",
        "            self.block.position = pos_block\n",
        "\n",
        "        # Run physics to take effect\n",
        "        self.space.step(1.0 / self.sim_hz)\n",
        "\n",
        "    def _set_state_local(self, state_local):\n",
        "        agent_pos_local = state_local[:2]\n",
        "        block_pose_local = state_local[2:]\n",
        "        tf_img_obj = st.AffineTransform(\n",
        "            translation=self.goal_pose[:2],\n",
        "            rotation=self.goal_pose[2])\n",
        "        tf_obj_new = st.AffineTransform(\n",
        "            translation=block_pose_local[:2],\n",
        "            rotation=block_pose_local[2]\n",
        "        )\n",
        "        tf_img_new = st.AffineTransform(\n",
        "            matrix=tf_img_obj.params @ tf_obj_new.params\n",
        "        )\n",
        "        agent_pos_new = tf_img_new(agent_pos_local)\n",
        "        new_state = np.array(\n",
        "            list(agent_pos_new[0]) + list(tf_img_new.translation) \\\n",
        "                + [tf_img_new.rotation])\n",
        "        self._set_state(new_state)\n",
        "        return new_state\n",
        "\n",
        "    def _setup(self):\n",
        "        self.space = pymunk.Space()\n",
        "        self.space.gravity = 0, 0\n",
        "        self.space.damping = 0\n",
        "        self.teleop = False\n",
        "        self.render_buffer = list()\n",
        "\n",
        "        # Add walls.\n",
        "        walls = [\n",
        "            self._add_segment((5, 506), (5, 5), 2),\n",
        "            self._add_segment((5, 5), (506, 5), 2),\n",
        "            self._add_segment((506, 5), (506, 506), 2),\n",
        "            self._add_segment((5, 506), (506, 506), 2)\n",
        "        ]\n",
        "        self.space.add(*walls)\n",
        "\n",
        "        # Add agent, block, and goal zone.\n",
        "        self.agent = self.add_circle((256, 400), 15)\n",
        "        self.block = self.add_tee((256, 300), 0)\n",
        "        self.goal_color = pygame.Color('LightGreen')\n",
        "        self.goal_pose = np.array([256,256,np.pi/4])  # x, y, theta (in radians)\n",
        "\n",
        "        # Add collision handeling\n",
        "        self.collision_handeler = self.space.add_collision_handler(0, 0)\n",
        "        self.collision_handeler.post_solve = self._handle_collision\n",
        "        self.n_contact_points = 0\n",
        "\n",
        "        self.max_score = 50 * 100\n",
        "        self.success_threshold = 0.95    # 95% coverage.\n",
        "\n",
        "    def _add_segment(self, a, b, radius):\n",
        "        shape = pymunk.Segment(self.space.static_body, a, b, radius)\n",
        "        shape.color = pygame.Color('LightGray')    # https://htmlcolorcodes.com/color-names\n",
        "        return shape\n",
        "\n",
        "    def add_circle(self, position, radius):\n",
        "        body = pymunk.Body(body_type=pymunk.Body.KINEMATIC)\n",
        "        body.position = position\n",
        "        body.friction = 1\n",
        "        shape = pymunk.Circle(body, radius)\n",
        "        shape.color = pygame.Color('RoyalBlue')\n",
        "        self.space.add(body, shape)\n",
        "        return body\n",
        "\n",
        "    def add_box(self, position, height, width):\n",
        "        mass = 1\n",
        "        inertia = pymunk.moment_for_box(mass, (height, width))\n",
        "        body = pymunk.Body(mass, inertia)\n",
        "        body.position = position\n",
        "        shape = pymunk.Poly.create_box(body, (height, width))\n",
        "        shape.color = pygame.Color('LightSlateGray')\n",
        "        self.space.add(body, shape)\n",
        "        return body\n",
        "\n",
        "    def add_tee(self, position, angle, scale=30, color='LightSlateGray', mask=pymunk.ShapeFilter.ALL_MASKS()):\n",
        "        mass = 1\n",
        "        length = 4\n",
        "        vertices1 = [(-length*scale/2, scale),\n",
        "                                 ( length*scale/2, scale),\n",
        "                                 ( length*scale/2, 0),\n",
        "                                 (-length*scale/2, 0)]\n",
        "        inertia1 = pymunk.moment_for_poly(mass, vertices=vertices1)\n",
        "        vertices2 = [(-scale/2, scale),\n",
        "                                 (-scale/2, length*scale),\n",
        "                                 ( scale/2, length*scale),\n",
        "                                 ( scale/2, scale)]\n",
        "        inertia2 = pymunk.moment_for_poly(mass, vertices=vertices1)\n",
        "        body = pymunk.Body(mass, inertia1 + inertia2)\n",
        "        shape1 = pymunk.Poly(body, vertices1)\n",
        "        shape2 = pymunk.Poly(body, vertices2)\n",
        "        shape1.color = pygame.Color(color)\n",
        "        shape2.color = pygame.Color(color)\n",
        "        shape1.filter = pymunk.ShapeFilter(mask=mask)\n",
        "        shape2.filter = pymunk.ShapeFilter(mask=mask)\n",
        "        body.center_of_gravity = (shape1.center_of_gravity + shape2.center_of_gravity) / 2\n",
        "        body.position = position\n",
        "        body.angle = angle\n",
        "        body.friction = 1\n",
        "        self.space.add(body, shape1, shape2)\n",
        "        return body\n",
        "\n",
        "\n",
        "class PushTImageEnv(PushTEnv):\n",
        "    metadata = {\"render.modes\": [\"rgb_array\"], \"video.frames_per_second\": 10}\n",
        "\n",
        "    def __init__(self,\n",
        "            legacy=False,\n",
        "            block_cog=None,\n",
        "            damping=None,\n",
        "            render_size=96):\n",
        "        super().__init__(\n",
        "            legacy=legacy,\n",
        "            block_cog=block_cog,\n",
        "            damping=damping,\n",
        "            render_size=render_size,\n",
        "            render_action=False)\n",
        "        ws = self.window_size\n",
        "        self.observation_space = spaces.Dict({\n",
        "            'image': spaces.Box(\n",
        "                low=0,\n",
        "                high=1,\n",
        "                shape=(3,render_size,render_size),\n",
        "                dtype=np.float32\n",
        "            ),\n",
        "            'agent_pos': spaces.Box(\n",
        "                low=0,\n",
        "                high=ws,\n",
        "                shape=(2,),\n",
        "                dtype=np.float32\n",
        "            )\n",
        "        })\n",
        "        self.render_cache = None\n",
        "\n",
        "    def _get_obs(self):\n",
        "        img = super()._render_frame(mode='rgb_array')\n",
        "\n",
        "        agent_pos = np.array(self.agent.position)\n",
        "        img_obs = np.moveaxis(img.astype(np.float32) / 255, -1, 0)\n",
        "        obs = {\n",
        "            'image': img_obs,\n",
        "            'agent_pos': agent_pos\n",
        "        }\n",
        "\n",
        "        # draw action\n",
        "        if self.latest_action is not None:\n",
        "            action = np.array(self.latest_action)\n",
        "            coord = (action / 512 * 96).astype(np.int32)\n",
        "            marker_size = int(8/96*self.render_size)\n",
        "            thickness = int(1/96*self.render_size)\n",
        "            cv2.drawMarker(img, coord,\n",
        "                color=(255,0,0), markerType=cv2.MARKER_CROSS,\n",
        "                markerSize=marker_size, thickness=thickness)\n",
        "        self.render_cache = img\n",
        "\n",
        "        return obs\n",
        "\n",
        "    def render(self, mode):\n",
        "        assert mode == 'rgb_array'\n",
        "\n",
        "        if self.render_cache is None:\n",
        "            self._get_obs()\n",
        "\n",
        "        return self.render_cache"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OknH8Qfqrtc9",
        "outputId": "c97c843e-0b23-4c0a-c123-cd72c407e163"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "obs['image'].shape: (3, 96, 96) float32, [0,1]\n",
            "obs['agent_pos'].shape: (2,) float32, [0,512]\n",
            "action.shape:  (2,) float32, [0,512]\n"
          ]
        }
      ],
      "source": [
        "#@markdown ### **Env Demo**\n",
        "#@markdown Standard Gym Env (0.21.0 API)\n",
        "\n",
        "# 0. create env object\n",
        "env = PushTImageEnv()\n",
        "\n",
        "# 1. seed env for initial state.\n",
        "# Seed 0-200 are used for the demonstration dataset.\n",
        "env.seed(1000)\n",
        "\n",
        "# 2. must reset before use\n",
        "obs, info = env.reset()\n",
        "\n",
        "# 3. 2D positional action space [0,512]\n",
        "action = env.action_space.sample()\n",
        "\n",
        "# 4. Standard gym step method\n",
        "obs, reward, terminated, truncated, info = env.step(action)\n",
        "\n",
        "# prints and explains each dimension of the observation and action vectors\n",
        "with np.printoptions(precision=4, suppress=True, threshold=5):\n",
        "    print(\"obs['image'].shape:\", obs['image'].shape, \"float32, [0,1]\")\n",
        "    print(\"obs['agent_pos'].shape:\", obs['agent_pos'].shape, \"float32, [0,512]\")\n",
        "    print(\"action.shape: \", action.shape, \"float32, [0,512]\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "vHepJOFBucwg"
      },
      "outputs": [],
      "source": [
        "#@markdown ### **Dataset**\n",
        "#@markdown\n",
        "#@markdown Defines `PushTImageDataset` and helper functions\n",
        "#@markdown\n",
        "#@markdown The dataset class\n",
        "#@markdown - Load data ((image, agent_pos), action) from a zarr storage\n",
        "#@markdown - Normalizes each dimension of agent_pos and action to [-1,1]\n",
        "#@markdown - Returns\n",
        "#@markdown  - All possible segments with length `pred_horizon`\n",
        "#@markdown  - Pads the beginning and the end of each episode with repetition\n",
        "#@markdown  - key `image`: shape (obs_hoirzon, 3, 96, 96)\n",
        "#@markdown  - key `agent_pos`: shape (obs_hoirzon, 2)\n",
        "#@markdown  - key `action`: shape (pred_horizon, 2)\n",
        "\n",
        "def create_sample_indices(\n",
        "        episode_ends:np.ndarray, sequence_length:int,\n",
        "        pad_before: int=0, pad_after: int=0):\n",
        "    indices = list()\n",
        "    for i in range(len(episode_ends)):\n",
        "        start_idx = 0\n",
        "        if i > 0:\n",
        "            start_idx = episode_ends[i-1]\n",
        "        end_idx = episode_ends[i]\n",
        "        episode_length = end_idx - start_idx\n",
        "\n",
        "        min_start = -pad_before\n",
        "        max_start = episode_length - sequence_length + pad_after\n",
        "\n",
        "        # range stops one idx before end\n",
        "        for idx in range(min_start, max_start+1):\n",
        "            buffer_start_idx = max(idx, 0) + start_idx\n",
        "            buffer_end_idx = min(idx+sequence_length, episode_length) + start_idx\n",
        "            start_offset = buffer_start_idx - (idx+start_idx)\n",
        "            end_offset = (idx+sequence_length+start_idx) - buffer_end_idx\n",
        "            sample_start_idx = 0 + start_offset\n",
        "            sample_end_idx = sequence_length - end_offset\n",
        "            indices.append([\n",
        "                buffer_start_idx, buffer_end_idx,\n",
        "                sample_start_idx, sample_end_idx])\n",
        "    indices = np.array(indices)\n",
        "    return indices\n",
        "\n",
        "\n",
        "def sample_sequence(train_data, sequence_length,\n",
        "                    buffer_start_idx, buffer_end_idx,\n",
        "                    sample_start_idx, sample_end_idx):\n",
        "    result = dict()\n",
        "    for key, input_arr in train_data.items():\n",
        "        sample = input_arr[buffer_start_idx:buffer_end_idx]\n",
        "        data = sample\n",
        "        if (sample_start_idx > 0) or (sample_end_idx < sequence_length):\n",
        "            data = np.zeros(\n",
        "                shape=(sequence_length,) + input_arr.shape[1:],\n",
        "                dtype=input_arr.dtype)\n",
        "            if sample_start_idx > 0:\n",
        "                data[:sample_start_idx] = sample[0]\n",
        "            if sample_end_idx < sequence_length:\n",
        "                data[sample_end_idx:] = sample[-1]\n",
        "            data[sample_start_idx:sample_end_idx] = sample\n",
        "        result[key] = data\n",
        "    return result\n",
        "\n",
        "# normalize data\n",
        "def get_data_stats(data):\n",
        "    data = data.reshape(-1,data.shape[-1])\n",
        "    stats = {\n",
        "        'min': np.min(data, axis=0),\n",
        "        'max': np.max(data, axis=0)\n",
        "    }\n",
        "    return stats\n",
        "\n",
        "def normalize_data(data, stats):\n",
        "    # nomalize to [0,1]\n",
        "    ndata = (data - stats['min']) / (stats['max'] - stats['min'])\n",
        "    # normalize to [-1, 1]\n",
        "    ndata = ndata * 2 - 1\n",
        "    return ndata\n",
        "\n",
        "def unnormalize_data(ndata, stats):\n",
        "    ndata = (ndata + 1) / 2\n",
        "    data = ndata * (stats['max'] - stats['min']) + stats['min']\n",
        "    return data\n",
        "\n",
        "# dataset\n",
        "class PushTImageDataset(torch.utils.data.Dataset):\n",
        "    def __init__(self,\n",
        "                 dataset_path: str,\n",
        "                 pred_horizon: int,\n",
        "                 obs_horizon: int,\n",
        "                 action_horizon: int):\n",
        "\n",
        "        # read from zarr dataset\n",
        "        dataset_root = zarr.open(dataset_path, 'r')\n",
        "\n",
        "        # float32, [0,1], (N,96,96,3)\n",
        "        train_image_data = dataset_root['data']['img'][:]\n",
        "        train_image_data = np.moveaxis(train_image_data, -1,1)\n",
        "        # (N,3,96,96)\n",
        "\n",
        "        # (N, D)\n",
        "        train_data = {\n",
        "            # first two dims of state vector are agent (i.e. gripper) locations\n",
        "            'agent_pos': dataset_root['data']['state'][:,:2],\n",
        "            'action': dataset_root['data']['action'][:]\n",
        "        }\n",
        "        episode_ends = dataset_root['meta']['episode_ends'][:]\n",
        "\n",
        "        # compute start and end of each state-action sequence\n",
        "        # also handles padding\n",
        "        indices = create_sample_indices(\n",
        "            episode_ends=episode_ends,\n",
        "            sequence_length=pred_horizon,\n",
        "            pad_before=obs_horizon-1,\n",
        "            pad_after=action_horizon-1)\n",
        "\n",
        "        # compute statistics and normalized data to [-1,1]\n",
        "        stats = dict()\n",
        "        normalized_train_data = dict()\n",
        "        for key, data in train_data.items():\n",
        "            stats[key] = get_data_stats(data)\n",
        "            normalized_train_data[key] = normalize_data(data, stats[key])\n",
        "\n",
        "        # images are already normalized\n",
        "        normalized_train_data['image'] = train_image_data\n",
        "\n",
        "        self.indices = indices\n",
        "        self.stats = stats\n",
        "        self.normalized_train_data = normalized_train_data\n",
        "        self.pred_horizon = pred_horizon\n",
        "        self.action_horizon = action_horizon\n",
        "        self.obs_horizon = obs_horizon\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.indices)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        # get the start/end indices for this datapoint\n",
        "        buffer_start_idx, buffer_end_idx, \\\n",
        "            sample_start_idx, sample_end_idx = self.indices[idx]\n",
        "\n",
        "        # get nomralized data using these indices\n",
        "        nsample = sample_sequence(\n",
        "            train_data=self.normalized_train_data,\n",
        "            sequence_length=self.pred_horizon,\n",
        "            buffer_start_idx=buffer_start_idx,\n",
        "            buffer_end_idx=buffer_end_idx,\n",
        "            sample_start_idx=sample_start_idx,\n",
        "            sample_end_idx=sample_end_idx\n",
        "        )\n",
        "\n",
        "        # discard unused observations\n",
        "        nsample['image'] = nsample['image'][:self.obs_horizon,:]\n",
        "        nsample['agent_pos'] = nsample['agent_pos'][:self.obs_horizon,:]\n",
        "        return nsample\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9ZiHF3lzvB6k",
        "outputId": "e6256ff1-ab20-41d4-a9ea-7c035196bf3c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "batch['image'].shape: torch.Size([64, 2, 3, 96, 96])\n",
            "batch['agent_pos'].shape: torch.Size([64, 2, 2])\n",
            "batch['action'].shape torch.Size([64, 16, 2])\n"
          ]
        }
      ],
      "source": [
        "#@markdown ### **Dataset Demo**\n",
        "\n",
        "# download demonstration data from Google Drive\n",
        "dataset_path = \"pusht_cchi_v7_replay.zarr.zip\"\n",
        "if not os.path.isfile(dataset_path):\n",
        "    id = \"1KY1InLurpMvJDRb14L9NlXT_fEsCvVUq&confirm=t\"\n",
        "    gdown.download(id=id, output=dataset_path, quiet=False)\n",
        "\n",
        "# parameters\n",
        "pred_horizon = 16\n",
        "obs_horizon = 2\n",
        "action_horizon = 8\n",
        "#|o|o|                             observations: 2\n",
        "#| |a|a|a|a|a|a|a|a|               actions executed: 8\n",
        "#|p|p|p|p|p|p|p|p|p|p|p|p|p|p|p|p| actions predicted: 16\n",
        "\n",
        "# create dataset from file\n",
        "dataset = PushTImageDataset(\n",
        "    dataset_path=dataset_path,\n",
        "    pred_horizon=pred_horizon,\n",
        "    obs_horizon=obs_horizon,\n",
        "    action_horizon=action_horizon\n",
        ")\n",
        "# save training data statistics (min, max) for each dim\n",
        "stats = dataset.stats\n",
        "\n",
        "# create dataloader\n",
        "dataloader = torch.utils.data.DataLoader(\n",
        "    dataset,\n",
        "    batch_size=64,\n",
        "    num_workers=4,\n",
        "    shuffle=True,\n",
        "    # accelerate cpu-gpu transfer\n",
        "    pin_memory=True,\n",
        "    # don't kill worker process afte each epoch\n",
        "    persistent_workers=True\n",
        ")\n",
        "\n",
        "# visualize data in batch\n",
        "batch = next(iter(dataloader))\n",
        "print(\"batch['image'].shape:\", batch['image'].shape)\n",
        "print(\"batch['agent_pos'].shape:\", batch['agent_pos'].shape)\n",
        "print(\"batch['action'].shape\", batch['action'].shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "X-XRB_g3vsgf"
      },
      "outputs": [],
      "source": [
        "#@markdown ### **Network**\n",
        "#@markdown\n",
        "#@markdown Defines a 1D UNet architecture `ConditionalUnet1D`\n",
        "#@markdown as the noies prediction network\n",
        "#@markdown\n",
        "#@markdown Components\n",
        "#@markdown - `SinusoidalPosEmb` Positional encoding for the diffusion iteration k\n",
        "#@markdown - `Downsample1d` Strided convolution to reduce temporal resolution\n",
        "#@markdown - `Upsample1d` Transposed convolution to increase temporal resolution\n",
        "#@markdown - `Conv1dBlock` Conv1d --> GroupNorm --> Mish\n",
        "#@markdown - `ConditionalResidualBlock1D` Takes two inputs `x` and `cond`. \\\n",
        "#@markdown `x` is passed through 2 `Conv1dBlock` stacked together with residual connection.\n",
        "#@markdown `cond` is applied to `x` with [FiLM](https://arxiv.org/abs/1709.07871) conditioning.\n",
        "\n",
        "class SinusoidalPosEmb(nn.Module):\n",
        "    def __init__(self, dim):\n",
        "        super().__init__()\n",
        "        self.dim = dim\n",
        "\n",
        "    def forward(self, x):\n",
        "        device = x.device\n",
        "        half_dim = self.dim // 2\n",
        "        emb = math.log(10000) / (half_dim - 1)\n",
        "        emb = torch.exp(torch.arange(half_dim, device=device) * -emb)\n",
        "        emb = x[:, None] * emb[None, :]\n",
        "        emb = torch.cat((emb.sin(), emb.cos()), dim=-1)\n",
        "        return emb\n",
        "\n",
        "\n",
        "class Downsample1d(nn.Module):\n",
        "    def __init__(self, dim):\n",
        "        super().__init__()\n",
        "        self.conv = nn.Conv1d(dim, dim, 3, 2, 1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.conv(x)\n",
        "\n",
        "class Upsample1d(nn.Module):\n",
        "    def __init__(self, dim):\n",
        "        super().__init__()\n",
        "        self.conv = nn.ConvTranspose1d(dim, dim, 4, 2, 1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.conv(x)\n",
        "\n",
        "\n",
        "class Conv1dBlock(nn.Module):\n",
        "    '''\n",
        "        Conv1d --> GroupNorm --> Mish\n",
        "    '''\n",
        "\n",
        "    def __init__(self, inp_channels, out_channels, kernel_size, n_groups=8):\n",
        "        super().__init__()\n",
        "\n",
        "        self.block = nn.Sequential(\n",
        "            nn.Conv1d(inp_channels, out_channels, kernel_size, padding=kernel_size // 2),\n",
        "            nn.GroupNorm(n_groups, out_channels),\n",
        "            nn.Mish(),\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.block(x)\n",
        "\n",
        "\n",
        "class ConditionalResidualBlock1D(nn.Module):\n",
        "    def __init__(self,\n",
        "            in_channels,\n",
        "            out_channels,\n",
        "            cond_dim,\n",
        "            kernel_size=3,\n",
        "            n_groups=8):\n",
        "        super().__init__()\n",
        "\n",
        "        self.blocks = nn.ModuleList([\n",
        "            Conv1dBlock(in_channels, out_channels, kernel_size, n_groups=n_groups),\n",
        "            Conv1dBlock(out_channels, out_channels, kernel_size, n_groups=n_groups),\n",
        "        ])\n",
        "\n",
        "        # FiLM modulation https://arxiv.org/abs/1709.07871\n",
        "        # predicts per-channel scale and bias\n",
        "        cond_channels = out_channels * 2\n",
        "        self.out_channels = out_channels\n",
        "        self.cond_encoder = nn.Sequential(\n",
        "            nn.Mish(),\n",
        "            nn.Linear(cond_dim, cond_channels),\n",
        "            nn.Unflatten(-1, (-1, 1))\n",
        "        )\n",
        "\n",
        "        # make sure dimensions compatible\n",
        "        self.residual_conv = nn.Conv1d(in_channels, out_channels, 1) \\\n",
        "            if in_channels != out_channels else nn.Identity()\n",
        "\n",
        "    def forward(self, x, cond):\n",
        "        '''\n",
        "            x : [ batch_size x in_channels x horizon ]\n",
        "            cond : [ batch_size x cond_dim]\n",
        "\n",
        "            returns:\n",
        "            out : [ batch_size x out_channels x horizon ]\n",
        "        '''\n",
        "        out = self.blocks[0](x)\n",
        "        embed = self.cond_encoder(cond)\n",
        "\n",
        "        embed = embed.reshape(\n",
        "            embed.shape[0], 2, self.out_channels, 1)\n",
        "        scale = embed[:,0,...]\n",
        "        bias = embed[:,1,...]\n",
        "        out = scale * out + bias\n",
        "\n",
        "        out = self.blocks[1](out)\n",
        "        out = out + self.residual_conv(x)\n",
        "        return out\n",
        "\n",
        "\n",
        "class ConditionalUnet1D(nn.Module):\n",
        "    def __init__(self,\n",
        "        input_dim,\n",
        "        global_cond_dim,\n",
        "        diffusion_step_embed_dim=256,\n",
        "        down_dims=[256,512,1024],\n",
        "        kernel_size=5,\n",
        "        n_groups=8\n",
        "        ):\n",
        "        \"\"\"\n",
        "        input_dim: Dim of actions.\n",
        "        global_cond_dim: Dim of global conditioning applied with FiLM\n",
        "          in addition to diffusion step embedding. This is usually obs_horizon * obs_dim\n",
        "        diffusion_step_embed_dim: Size of positional encoding for diffusion iteration k\n",
        "        down_dims: Channel size for each UNet level.\n",
        "          The length of this array determines numebr of levels.\n",
        "        kernel_size: Conv kernel size\n",
        "        n_groups: Number of groups for GroupNorm\n",
        "        \"\"\"\n",
        "\n",
        "        super().__init__()\n",
        "        all_dims = [input_dim] + list(down_dims)\n",
        "        start_dim = down_dims[0]\n",
        "\n",
        "        dsed = diffusion_step_embed_dim\n",
        "        diffusion_step_encoder = nn.Sequential(\n",
        "            SinusoidalPosEmb(dsed),\n",
        "            nn.Linear(dsed, dsed * 4),\n",
        "            nn.Mish(),\n",
        "            nn.Linear(dsed * 4, dsed),\n",
        "        )\n",
        "        cond_dim = dsed + global_cond_dim\n",
        "\n",
        "        in_out = list(zip(all_dims[:-1], all_dims[1:]))\n",
        "        mid_dim = all_dims[-1]\n",
        "        self.mid_modules = nn.ModuleList([\n",
        "            ConditionalResidualBlock1D(\n",
        "                mid_dim, mid_dim, cond_dim=cond_dim,\n",
        "                kernel_size=kernel_size, n_groups=n_groups\n",
        "            ),\n",
        "            ConditionalResidualBlock1D(\n",
        "                mid_dim, mid_dim, cond_dim=cond_dim,\n",
        "                kernel_size=kernel_size, n_groups=n_groups\n",
        "            ),\n",
        "        ])\n",
        "\n",
        "        down_modules = nn.ModuleList([])\n",
        "        for ind, (dim_in, dim_out) in enumerate(in_out):\n",
        "            is_last = ind >= (len(in_out) - 1)\n",
        "            down_modules.append(nn.ModuleList([\n",
        "                ConditionalResidualBlock1D(\n",
        "                    dim_in, dim_out, cond_dim=cond_dim,\n",
        "                    kernel_size=kernel_size, n_groups=n_groups),\n",
        "                ConditionalResidualBlock1D(\n",
        "                    dim_out, dim_out, cond_dim=cond_dim,\n",
        "                    kernel_size=kernel_size, n_groups=n_groups),\n",
        "                Downsample1d(dim_out) if not is_last else nn.Identity()\n",
        "            ]))\n",
        "\n",
        "        up_modules = nn.ModuleList([])\n",
        "        for ind, (dim_in, dim_out) in enumerate(reversed(in_out[1:])):\n",
        "            is_last = ind >= (len(in_out) - 1)\n",
        "            up_modules.append(nn.ModuleList([\n",
        "                ConditionalResidualBlock1D(\n",
        "                    dim_out*2, dim_in, cond_dim=cond_dim,\n",
        "                    kernel_size=kernel_size, n_groups=n_groups),\n",
        "                ConditionalResidualBlock1D(\n",
        "                    dim_in, dim_in, cond_dim=cond_dim,\n",
        "                    kernel_size=kernel_size, n_groups=n_groups),\n",
        "                Upsample1d(dim_in) if not is_last else nn.Identity()\n",
        "            ]))\n",
        "\n",
        "        final_conv = nn.Sequential(\n",
        "            Conv1dBlock(start_dim, start_dim, kernel_size=kernel_size),\n",
        "            nn.Conv1d(start_dim, input_dim, 1),\n",
        "        )\n",
        "\n",
        "        self.diffusion_step_encoder = diffusion_step_encoder\n",
        "        self.up_modules = up_modules\n",
        "        self.down_modules = down_modules\n",
        "        self.final_conv = final_conv\n",
        "\n",
        "        print(\"number of parameters: {:e}\".format(\n",
        "            sum(p.numel() for p in self.parameters()))\n",
        "        )\n",
        "\n",
        "    def forward(self,\n",
        "            sample: torch.Tensor,\n",
        "            timestep: Union[torch.Tensor, float, int],\n",
        "            global_cond=None):\n",
        "        \"\"\"\n",
        "        x: (B,T,input_dim)\n",
        "        timestep: (B,) or int, diffusion step\n",
        "        global_cond: (B,global_cond_dim)\n",
        "        output: (B,T,input_dim)\n",
        "        \"\"\"\n",
        "        # (B,T,C)\n",
        "        sample = sample.moveaxis(-1,-2)\n",
        "        # (B,C,T)\n",
        "\n",
        "        # 1. time\n",
        "        timesteps = timestep\n",
        "        if not torch.is_tensor(timesteps):\n",
        "            # TODO: this requires sync between CPU and GPU. So try to pass timesteps as tensors if you can\n",
        "            timesteps = torch.tensor([timesteps], dtype=torch.long, device=sample.device)\n",
        "        elif torch.is_tensor(timesteps) and len(timesteps.shape) == 0:\n",
        "            timesteps = timesteps[None].to(sample.device)\n",
        "        # broadcast to batch dimension in a way that's compatible with ONNX/Core ML\n",
        "        timesteps = timesteps.expand(sample.shape[0])\n",
        "\n",
        "        global_feature = self.diffusion_step_encoder(timesteps)\n",
        "\n",
        "        if global_cond is not None:\n",
        "            global_feature = torch.cat([\n",
        "                global_feature, global_cond\n",
        "            ], axis=-1)\n",
        "\n",
        "        x = sample\n",
        "        h = []\n",
        "        for idx, (resnet, resnet2, downsample) in enumerate(self.down_modules):\n",
        "            x = resnet(x, global_feature)\n",
        "            x = resnet2(x, global_feature)\n",
        "            h.append(x)\n",
        "            x = downsample(x)\n",
        "\n",
        "        for mid_module in self.mid_modules:\n",
        "            x = mid_module(x, global_feature)\n",
        "\n",
        "        for idx, (resnet, resnet2, upsample) in enumerate(self.up_modules):\n",
        "            x = torch.cat((x, h.pop()), dim=1)\n",
        "            x = resnet(x, global_feature)\n",
        "            x = resnet2(x, global_feature)\n",
        "            x = upsample(x)\n",
        "\n",
        "        x = self.final_conv(x)\n",
        "\n",
        "        # (B,C,T)\n",
        "        x = x.moveaxis(-1,-2)\n",
        "        # (B,T,C)\n",
        "        return x\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "yXq4r744aMh1"
      },
      "outputs": [],
      "source": [
        "#@markdown ### **Vision Encoder**\n",
        "#@markdown\n",
        "#@markdown Defines helper functions:\n",
        "#@markdown - `get_resnet` to initialize standard ResNet vision encoder\n",
        "#@markdown - `replace_bn_with_gn` to replace all BatchNorm layers with GroupNorm\n",
        "\n",
        "def get_resnet(name:str, weights=None, **kwargs) -> nn.Module:\n",
        "    \"\"\"\n",
        "    name: resnet18, resnet34, resnet50\n",
        "    weights: \"IMAGENET1K_V1\", None\n",
        "    \"\"\"\n",
        "    # Use standard ResNet implementation from torchvision\n",
        "    func = getattr(torchvision.models, name)\n",
        "    resnet = func(weights=weights, **kwargs)\n",
        "\n",
        "    # remove the final fully connected layer\n",
        "    # for resnet18, the output dim should be 512\n",
        "    resnet.fc = torch.nn.Identity()\n",
        "    return resnet\n",
        "\n",
        "\n",
        "def replace_submodules(\n",
        "        root_module: nn.Module,\n",
        "        predicate: Callable[[nn.Module], bool],\n",
        "        func: Callable[[nn.Module], nn.Module]) -> nn.Module:\n",
        "    \"\"\"\n",
        "    Replace all submodules selected by the predicate with\n",
        "    the output of func.\n",
        "\n",
        "    predicate: Return true if the module is to be replaced.\n",
        "    func: Return new module to use.\n",
        "    \"\"\"\n",
        "    if predicate(root_module):\n",
        "        return func(root_module)\n",
        "\n",
        "    bn_list = [k.split('.') for k, m\n",
        "        in root_module.named_modules(remove_duplicate=True)\n",
        "        if predicate(m)]\n",
        "    for *parent, k in bn_list:\n",
        "        parent_module = root_module\n",
        "        if len(parent) > 0:\n",
        "            parent_module = root_module.get_submodule('.'.join(parent))\n",
        "        if isinstance(parent_module, nn.Sequential):\n",
        "            src_module = parent_module[int(k)]\n",
        "        else:\n",
        "            src_module = getattr(parent_module, k)\n",
        "        tgt_module = func(src_module)\n",
        "        if isinstance(parent_module, nn.Sequential):\n",
        "            parent_module[int(k)] = tgt_module\n",
        "        else:\n",
        "            setattr(parent_module, k, tgt_module)\n",
        "    # verify that all modules are replaced\n",
        "    bn_list = [k.split('.') for k, m\n",
        "        in root_module.named_modules(remove_duplicate=True)\n",
        "        if predicate(m)]\n",
        "    assert len(bn_list) == 0\n",
        "    return root_module\n",
        "\n",
        "def replace_bn_with_gn(\n",
        "    root_module: nn.Module,\n",
        "    features_per_group: int=16) -> nn.Module:\n",
        "    \"\"\"\n",
        "    Relace all BatchNorm layers with GroupNorm.\n",
        "    \"\"\"\n",
        "    replace_submodules(\n",
        "        root_module=root_module,\n",
        "        predicate=lambda x: isinstance(x, nn.BatchNorm2d),\n",
        "        func=lambda x: nn.GroupNorm(\n",
        "            num_groups=x.num_features//features_per_group,\n",
        "            num_channels=x.num_features)\n",
        "    )\n",
        "    return root_module\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4APZkqh336-M",
        "outputId": "e362d582-ceac-4cdd-e866-c34858593696"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "number of parameters: 7.994727e+07\n"
          ]
        }
      ],
      "source": [
        "#@markdown ### **Network Demo**\n",
        "\n",
        "# construct ResNet18 encoder\n",
        "# if you have multiple camera views, use seperate encoder weights for each view.\n",
        "vision_encoder = get_resnet('resnet18')\n",
        "\n",
        "# IMPORTANT!\n",
        "# replace all BatchNorm with GroupNorm to work with EMA\n",
        "# performance will tank if you forget to do this!\n",
        "vision_encoder = replace_bn_with_gn(vision_encoder)\n",
        "\n",
        "# ResNet18 has output dim of 512\n",
        "vision_feature_dim = 512\n",
        "# agent_pos is 2 dimensional\n",
        "lowdim_obs_dim = 2\n",
        "# observation feature has 514 dims in total per step\n",
        "obs_dim = vision_feature_dim + lowdim_obs_dim\n",
        "action_dim = 2\n",
        "\n",
        "# create network object\n",
        "noise_pred_net = ConditionalUnet1D(\n",
        "    input_dim=action_dim,\n",
        "    global_cond_dim=obs_dim*obs_horizon\n",
        ")\n",
        "\n",
        "# the final arch has 2 parts\n",
        "nets = nn.ModuleDict({\n",
        "    'vision_encoder': vision_encoder,\n",
        "    'noise_pred_net': noise_pred_net\n",
        "})\n",
        "\n",
        "# demo\n",
        "with torch.no_grad():\n",
        "    # example inputs\n",
        "    image = torch.zeros((1, obs_horizon,3,96,96))\n",
        "    agent_pos = torch.zeros((1, obs_horizon, 2))\n",
        "    # vision encoder\n",
        "    image_features = nets['vision_encoder'](\n",
        "        image.flatten(end_dim=1))\n",
        "    # (2,512)\n",
        "    image_features = image_features.reshape(*image.shape[:2],-1)\n",
        "    # (1,2,512)\n",
        "    obs = torch.cat([image_features, agent_pos],dim=-1)\n",
        "    # (1,2,514)\n",
        "\n",
        "    noised_action = torch.randn((1, pred_horizon, action_dim))\n",
        "    diffusion_iter = torch.zeros((1,))\n",
        "\n",
        "    # the noise prediction network\n",
        "    # takes noisy action, diffusion iteration and observation as input\n",
        "    # predicts the noise added to action\n",
        "    noise = nets['noise_pred_net'](\n",
        "        sample=noised_action,\n",
        "        timestep=diffusion_iter,\n",
        "        global_cond=obs.flatten(start_dim=1))\n",
        "\n",
        "    # illustration of removing noise\n",
        "    # the actual noise removal is performed by NoiseScheduler\n",
        "    # and is dependent on the diffusion noise schedule\n",
        "    denoised_action = noised_action - noise\n",
        "\n",
        "# for this demo, we use DDPMScheduler with 100 diffusion iterations\n",
        "num_diffusion_iters = 100\n",
        "noise_scheduler = DDPMScheduler(\n",
        "    num_train_timesteps=num_diffusion_iters,\n",
        "    # the choise of beta schedule has big impact on performance\n",
        "    # we found squared cosine works the best\n",
        "    beta_schedule='squaredcos_cap_v2',\n",
        "    # clip output to [-1,1] to improve stability\n",
        "    clip_sample=True,\n",
        "    # our network predicts noise (instead of denoised action)\n",
        "    prediction_type='epsilon'\n",
        ")\n",
        "\n",
        "# device transfer\n",
        "device = torch.device('cuda')\n",
        "_ = nets.to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 81,
          "referenced_widgets": [
            "b34bf5a5d603446fb453bbed31c4469c",
            "0873a2dee0e44b0fb3e8445d94c27171",
            "410476fa4ac14dd2b78377f4d779402f",
            "09152dbe3c8543aa809aa592afdc53f1",
            "e2a91fa6d1514913892c0def2e2ecf78",
            "7fd765bcd2a34db49a02839ba1c4f518",
            "d9054c34284045eda3546a21bb5fafc3",
            "a92fc95c6a3d496997da90c87e24ba01",
            "9a98272475d940b1b98438c4d02dcc05",
            "47b6383ed3b64b7e8c7e66d0e7a468d9",
            "1cdde5afac8041bf9b75e0e80bd80630",
            "70b4b657d68648d9be98c099d061cd5a",
            "8c0237e38cfd4143aa423dea26637965",
            "44c486fa8c4241f4a1a245f4e24da769",
            "12ef3c026774405cb91faf18d7fd8afa",
            "99c0577d549c4dd4a61d9ec0cf6254d5",
            "5124950790874225b5cca7556f122f9a",
            "f609505b750747dcaff8a950131743e9",
            "3c0a27b6addb4c6a977824995548fe90",
            "d14f2c65ef9348348250af2df0f32963",
            "eb23edb22d624aee9fd55ab05e2a517e",
            "a073d659b0f347c9b30c343430d7f6aa",
            "7508fbad995648a39d2a55953d000786",
            "9009dc5a656c4befbf513f2574df5a7d",
            "479d2f35498b4fbea77057f3f26fd287",
            "16b5928585984a1b81b809717f125489",
            "9d436c7ee90349a5966f025d095dd0cc",
            "3e503eeff5d94f0e9dc8a3d31190c6a2",
            "4abc5a8b257240b99535a6abe5e00ef6",
            "6c25264289e3411db29f6f8db936b00f",
            "a0ff8cd1b00544caa12cbd809524dd15",
            "1faac530b70b41a58a8c9c0cf44af69c",
            "7cfefcf49a9a426da4e9203ec4debe38",
            "5f96241543b441fcb13c16d4ca476405",
            "e6bbb6ce052045ca895b526c620d8847",
            "5c1c61cd14fb4aa8b335684fbf652a29",
            "a5a2bc5dc0b54a4796e574308bb6c4bc",
            "febe66177c604395a78be993eeff7c6d",
            "6de3445a866442aa9cc7d855cb0d0740",
            "353cb60a2a73417b81ccbb5e52480ed3",
            "69f323a406004822bf1a0bfd79767c9a",
            "88a8f5924a1e4a86805e314dd90c17be",
            "9ada44d21f234712ac5df797c730495a",
            "c777ac64366c40ea8a1f63408879c2ab"
          ]
        },
        "id": "93E9RdnR4D8v",
        "outputId": "6592f2ca-4d83-41a4-c650-564042a44b0d"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch:   0%|          | 0/100 [00:00<?, ?it/s]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch:  26%|██▌       | 26/100 [07:03<20:04, 16.28s/it, loss=0.0292]\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[13], line 66\u001b[0m\n\u001b[1;32m     59\u001b[0m timesteps \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mrandint(\n\u001b[1;32m     60\u001b[0m     \u001b[38;5;241m0\u001b[39m, noise_scheduler\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mnum_train_timesteps,\n\u001b[1;32m     61\u001b[0m     (B,), device\u001b[38;5;241m=\u001b[39mdevice\n\u001b[1;32m     62\u001b[0m )\u001b[38;5;241m.\u001b[39mlong()\n\u001b[1;32m     64\u001b[0m \u001b[38;5;66;03m# add noise to the clean images according to the noise magnitude at each diffusion iteration\u001b[39;00m\n\u001b[1;32m     65\u001b[0m \u001b[38;5;66;03m# (this is the forward diffusion process)\u001b[39;00m\n\u001b[0;32m---> 66\u001b[0m noisy_actions \u001b[38;5;241m=\u001b[39m \u001b[43mnoise_scheduler\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madd_noise\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     67\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnaction\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnoise\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimesteps\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     69\u001b[0m \u001b[38;5;66;03m# predict the noise residual\u001b[39;00m\n\u001b[1;32m     70\u001b[0m noise_pred \u001b[38;5;241m=\u001b[39m noise_pred_net(\n\u001b[1;32m     71\u001b[0m     noisy_actions, timesteps, global_cond\u001b[38;5;241m=\u001b[39mobs_cond)\n",
            "File \u001b[0;32m~/miniforge3/envs/action-diff/lib/python3.10/site-packages/diffusers/schedulers/scheduling_ddpm.py:461\u001b[0m, in \u001b[0;36mDDPMScheduler.add_noise\u001b[0;34m(self, original_samples, noise, timesteps)\u001b[0m\n\u001b[1;32m    454\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21madd_noise\u001b[39m(\n\u001b[1;32m    455\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    456\u001b[0m     original_samples: torch\u001b[38;5;241m.\u001b[39mFloatTensor,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    459\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m torch\u001b[38;5;241m.\u001b[39mFloatTensor:\n\u001b[1;32m    460\u001b[0m     \u001b[38;5;66;03m# Make sure alphas_cumprod and timestep have same device and dtype as original_samples\u001b[39;00m\n\u001b[0;32m--> 461\u001b[0m     alphas_cumprod \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43malphas_cumprod\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moriginal_samples\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moriginal_samples\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    462\u001b[0m     timesteps \u001b[38;5;241m=\u001b[39m timesteps\u001b[38;5;241m.\u001b[39mto(original_samples\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[1;32m    464\u001b[0m     sqrt_alpha_prod \u001b[38;5;241m=\u001b[39m alphas_cumprod[timesteps] \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m \u001b[38;5;241m0.5\u001b[39m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "#@markdown ### **Training**\n",
        "#@markdown\n",
        "#@markdown Takes about 2.5 hours. If you don't want to wait, skip to the next cell\n",
        "#@markdown to load pre-trained weights\n",
        "\n",
        "num_epochs = 200\n",
        "\n",
        "# Exponential Moving Average\n",
        "# accelerates training and improves stability\n",
        "# holds a copy of the model weights\n",
        "ema = EMAModel(\n",
        "    parameters=nets.parameters(),\n",
        "    power=0.75)\n",
        "\n",
        "# Standard ADAM optimizer\n",
        "# Note that EMA parametesr are not optimized\n",
        "optimizer = torch.optim.AdamW(\n",
        "    params=nets.parameters(),\n",
        "    lr=1e-4, weight_decay=1e-6)\n",
        "\n",
        "# Cosine LR schedule with linear warmup\n",
        "lr_scheduler = get_scheduler(\n",
        "    name='cosine',\n",
        "    optimizer=optimizer,\n",
        "    num_warmup_steps=500,\n",
        "    num_training_steps=len(dataloader) * num_epochs\n",
        ")\n",
        "\n",
        "with tqdm(range(num_epochs), desc='Epoch') as tglobal:\n",
        "    # epoch loop\n",
        "    for epoch_idx in tglobal:\n",
        "        epoch_loss = list()\n",
        "        # batch loop\n",
        "        with tqdm(dataloader, desc='Batch', leave=False) as tepoch:\n",
        "            for nbatch in tepoch:\n",
        "                # data normalized in dataset\n",
        "                # device transfer\n",
        "                nimage = nbatch['image'][:,:obs_horizon].to(device)\n",
        "                nagent_pos = nbatch['agent_pos'][:,:obs_horizon].to(device)\n",
        "                naction = nbatch['action'].to(device)\n",
        "                B = nagent_pos.shape[0]\n",
        "\n",
        "                # encoder vision features\n",
        "                image_features = nets['vision_encoder'](\n",
        "                    nimage.flatten(end_dim=1))\n",
        "                image_features = image_features.reshape(\n",
        "                    *nimage.shape[:2],-1)\n",
        "                # (B,obs_horizon,D)\n",
        "\n",
        "                # concatenate vision feature and low-dim obs\n",
        "                obs_features = torch.cat([image_features, nagent_pos], dim=-1)\n",
        "                obs_cond = obs_features.flatten(start_dim=1)\n",
        "                # (B, obs_horizon * obs_dim)\n",
        "\n",
        "                # sample noise to add to actions\n",
        "                noise = torch.randn(naction.shape, device=device)\n",
        "\n",
        "                # sample a diffusion iteration for each data point\n",
        "                timesteps = torch.randint(\n",
        "                    0, noise_scheduler.config.num_train_timesteps,\n",
        "                    (B,), device=device\n",
        "                ).long()\n",
        "\n",
        "                # add noise to the clean images according to the noise magnitude at each diffusion iteration\n",
        "                # (this is the forward diffusion process)\n",
        "                noisy_actions = noise_scheduler.add_noise(\n",
        "                    naction, noise, timesteps)\n",
        "\n",
        "                # predict the noise residual\n",
        "                noise_pred = noise_pred_net(\n",
        "                    noisy_actions, timesteps, global_cond=obs_cond)\n",
        "\n",
        "                # L2 loss\n",
        "                loss = nn.functional.mse_loss(noise_pred, noise)\n",
        "\n",
        "                # optimize\n",
        "                loss.backward()\n",
        "                optimizer.step()\n",
        "                optimizer.zero_grad()\n",
        "                # step lr scheduler every batch\n",
        "                # this is different from standard pytorch behavior\n",
        "                lr_scheduler.step()\n",
        "\n",
        "                # update Exponential Moving Average of the model weights\n",
        "                ema.step(nets.parameters())\n",
        "\n",
        "                # logging\n",
        "                loss_cpu = loss.item()\n",
        "                epoch_loss.append(loss_cpu)\n",
        "                tepoch.set_postfix(loss=loss_cpu)\n",
        "        tglobal.set_postfix(loss=np.mean(epoch_loss))\n",
        "\n",
        "# Weights of the EMA model\n",
        "# is used for inference\n",
        "ema_nets = nets\n",
        "ema.copy_to(ema_nets.parameters())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [],
      "source": [
        "save_path = 'ema_100ep.pt'\n",
        "# torch.save({\n",
        "#     'model_state_dict': ema_nets.state_dict()\n",
        "# }, save_path)\n",
        "\n",
        "# reload from checkpoint\n",
        "reload = True\n",
        "\n",
        "if reload:\n",
        "    ema_nets = nn.ModuleDict({\n",
        "        'vision_encoder': vision_encoder,\n",
        "        'noise_pred_net': noise_pred_net\n",
        "    })\n",
        "\n",
        "    checkpoint = torch.load(save_path, map_location='cuda')\n",
        "\n",
        "    nets.load_state_dict(checkpoint['model_state_dict'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6F3hUbIuxGdO",
        "outputId": "36fa4685-4c4a-4ef3-a0a5-add134288f88"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Skipped pretrained weight loading.\n"
          ]
        }
      ],
      "source": [
        "#@markdown ### **Loading Pretrained Checkpoint**\n",
        "#@markdown Set `load_pretrained = True` to load pretrained weights.\n",
        "\n",
        "load_pretrained = False\n",
        "if load_pretrained:\n",
        "  ckpt_path = \"pusht_vision_100ep.ckpt\"\n",
        "  if not os.path.isfile(ckpt_path):\n",
        "      id = \"1XKpfNSlwYMGaF5CncoFaLKCDTWoLAHf1&confirm=t\"\n",
        "      gdown.download(id=id, output=ckpt_path, quiet=False)\n",
        "\n",
        "  state_dict = torch.load(ckpt_path, map_location='cuda')\n",
        "  ema_nets = nets\n",
        "  ema_nets.load_state_dict(state_dict)\n",
        "  print('Pretrained weights loaded.')\n",
        "else:\n",
        "  print(\"Skipped pretrained weight loading.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 327,
          "referenced_widgets": [
            "b0a9f64f47d34769a47e165291d2c550",
            "2c31ffecd0494e2a8d0a8cefbea5df8a",
            "1d0a57ed8e914d31bcc1c36a56451df7",
            "e1bb86eb510b47d9ac2311926455bf1f",
            "182afbf676cd4c0982b90890bbdbeeef",
            "5d4a78f691ec4555bf179e5ef5d828ac",
            "1b96a78d8b8542eb830e3c446a0dcf42",
            "4cc800669dfd45a784864dd4a3881daa",
            "95dc6c44f97e4e8882a3657bd2fd66fb",
            "333b5148e59e47f3998a5cf5df531baf",
            "185ce2207cec4ae1a6ffdecadae23894"
          ]
        },
        "id": "OyLjlNQk5nr9",
        "outputId": "4641c055-a534-48e2-cc26-0d1056a004ba"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Eval PushTImageEnv:   0%|          | 0/200 [00:00<?, ?it/s]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Eval PushTImageEnv:  55%|█████▌    | 110/200 [00:08<00:06, 13.32it/s, reward=1]    "
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Score:  1.0\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<video controls  width=\"256\"  height=\"256\">\n",
              " <source src=\"data:video/mp4;base64,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\" type=\"video/mp4\">\n",
              " Your browser does not support the video tag.\n",
              " </video>"
            ],
            "text/plain": [
              "<IPython.core.display.Video object>"
            ]
          },
          "execution_count": 63,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#@markdown ### **Inference**\n",
        "\n",
        "# limit enviornment interaction to 200 steps before termination\n",
        "max_steps = 200\n",
        "env = PushTImageEnv()\n",
        "# use a seed >200 to avoid initial states seen in the training dataset\n",
        "env.seed(100000)\n",
        "\n",
        "# get first observation\n",
        "obs, info = env.reset()\n",
        "\n",
        "# keep a queue of last 2 steps of observations\n",
        "obs_deque = collections.deque(\n",
        "    [obs] * obs_horizon, maxlen=obs_horizon)\n",
        "# save visualization and rewards\n",
        "imgs = [env.render(mode='rgb_array')]\n",
        "rewards = list()\n",
        "done = False\n",
        "step_idx = 0\n",
        "\n",
        "with tqdm(total=max_steps, desc=\"Eval PushTImageEnv\") as pbar:\n",
        "    while not done:\n",
        "        B = 1\n",
        "        # stack the last obs_horizon number of observations\n",
        "        images = np.stack([x['image'] for x in obs_deque])\n",
        "        agent_poses = np.stack([x['agent_pos'] for x in obs_deque])\n",
        "\n",
        "        # normalize observation\n",
        "        nagent_poses = normalize_data(agent_poses, stats=stats['agent_pos'])\n",
        "        # images are already normalized to [0,1]\n",
        "        nimages = images\n",
        "\n",
        "        # device transfer\n",
        "        nimages = torch.from_numpy(nimages).to(device, dtype=torch.float32)\n",
        "        # (2,3,96,96)\n",
        "        nagent_poses = torch.from_numpy(nagent_poses).to(device, dtype=torch.float32)\n",
        "        # (2,2)\n",
        "\n",
        "        # infer action\n",
        "        with torch.no_grad():\n",
        "            # get image features\n",
        "            image_features = ema_nets['vision_encoder'](nimages)\n",
        "            # (2,512)\n",
        "\n",
        "            # concat with low-dim observations\n",
        "            obs_features = torch.cat([image_features, nagent_poses], dim=-1)\n",
        "\n",
        "            # reshape observation to (B,obs_horizon*obs_dim)\n",
        "            obs_cond = obs_features.unsqueeze(0).flatten(start_dim=1)\n",
        "\n",
        "            # initialize action from Guassian noise\n",
        "            noisy_action = torch.randn(\n",
        "                (B, pred_horizon, action_dim), device=device)\n",
        "            naction = noisy_action\n",
        "\n",
        "            # init scheduler\n",
        "            noise_scheduler.set_timesteps(num_diffusion_iters)\n",
        "\n",
        "            for k in noise_scheduler.timesteps:\n",
        "                # predict noise\n",
        "                noise_pred = ema_nets['noise_pred_net'](\n",
        "                    sample=naction,\n",
        "                    timestep=k,\n",
        "                    global_cond=obs_cond\n",
        "                )\n",
        "\n",
        "                # inverse diffusion step (remove noise)\n",
        "                naction = noise_scheduler.step(\n",
        "                    model_output=noise_pred,\n",
        "                    timestep=k,\n",
        "                    sample=naction\n",
        "                ).prev_sample\n",
        "\n",
        "        # unnormalize action\n",
        "        naction = naction.detach().to('cpu').numpy()\n",
        "        # (B, pred_horizon, action_dim)\n",
        "        naction = naction[0]\n",
        "        action_pred = unnormalize_data(naction, stats=stats['action'])\n",
        "\n",
        "        # only take action_horizon number of actions\n",
        "        start = obs_horizon - 1\n",
        "        end = start + action_horizon\n",
        "        action = action_pred[start:end,:]\n",
        "        # (action_horizon, action_dim)\n",
        "\n",
        "        # execute action_horizon number of steps\n",
        "        # without replanning\n",
        "        for i in range(len(action)):\n",
        "            # stepping env\n",
        "            obs, reward, done, _, info = env.step(action[i])\n",
        "            # save observations\n",
        "            obs_deque.append(obs)\n",
        "            # and reward/vis\n",
        "            rewards.append(reward)\n",
        "            imgs.append(env.render(mode='rgb_array'))\n",
        "\n",
        "            # update progress bar\n",
        "            step_idx += 1\n",
        "            pbar.update(1)\n",
        "            pbar.set_postfix(reward=reward)\n",
        "            if step_idx > max_steps:\n",
        "                done = True\n",
        "            if done:\n",
        "                break\n",
        "\n",
        "# print out the maximum target coverage\n",
        "print('Score: ', max(rewards))\n",
        "\n",
        "# visualize\n",
        "from IPython.display import Video\n",
        "vwrite('vis.mp4', imgs)\n",
        "Video('vis.mp4', embed=True, width=256, height=256)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Push-T Domain Randomization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {},
      "outputs": [],
      "source": [
        "env = PushTImageEnv()\n",
        "env.seed(350)\n",
        "# get first observation\n",
        "obs, info = env.reset()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "image/jpeg": "/9j/4AAQSkZJRgABAQAAAQABAAD/2wBDAAgGBgcGBQgHBwcJCQgKDBQNDAsLDBkSEw8UHRofHh0aHBwgJC4nICIsIxwcKDcpLDAxNDQ0Hyc5PTgyPC4zNDL/2wBDAQkJCQwLDBgNDRgyIRwhMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjL/wAARCABgAGADASIAAhEBAxEB/8QAHwAAAQUBAQEBAQEAAAAAAAAAAAECAwQFBgcICQoL/8QAtRAAAgEDAwIEAwUFBAQAAAF9AQIDAAQRBRIhMUEGE1FhByJxFDKBkaEII0KxwRVS0fAkM2JyggkKFhcYGRolJicoKSo0NTY3ODk6Q0RFRkdISUpTVFVWV1hZWmNkZWZnaGlqc3R1dnd4eXqDhIWGh4iJipKTlJWWl5iZmqKjpKWmp6ipqrKztLW2t7i5usLDxMXGx8jJytLT1NXW19jZ2uHi4+Tl5ufo6erx8vP09fb3+Pn6/8QAHwEAAwEBAQEBAQEBAQAAAAAAAAECAwQFBgcICQoL/8QAtREAAgECBAQDBAcFBAQAAQJ3AAECAxEEBSExBhJBUQdhcRMiMoEIFEKRobHBCSMzUvAVYnLRChYkNOEl8RcYGRomJygpKjU2Nzg5OkNERUZHSElKU1RVVldYWVpjZGVmZ2hpanN0dXZ3eHl6goOEhYaHiImKkpOUlZaXmJmaoqOkpaanqKmqsrO0tba3uLm6wsPExcbHyMnK0tPU1dbX2Nna4uPk5ebn6Onq8vP09fb3+Pn6/9oADAMBAAIRAxEAPwD3mONWTc24kk/xH1p3kp/tf99GiH/V/if51JQBH5Kf7X/fRo8lP9r/AL6NSUUAR+Sn+1/30aPJT/a/76NSUyOWOZS0UiOoYqSrAgEHBH1BGKAE8lP9r/vo0eSn+1/30akooAj8lP8Aa/76NHkp/tf99GpKKAI/JT/a/wC+jTZI1VNy7gQR/EfWpqjm/wBX+I/nQAQ/6v8AE/zqSo4f9X+J/nUlABRRRQBXv7Y3unXVqspiaeJ4xIBkpuBGfwzXPeDfDN14eS7a7mhZ5ygCw5IAXPOSB/ePGO3fPHU0VtGvONOVJbPf5EOCclJ7oKKKKxLCiiigAqOb/V/iP51JUc3+r/EfzoAIf9X+J/nUlRw/6v8AE/zqSgAooooA8+8bIra+m5Q3+jIfm5x8zjj06Cur8Mz/AGjw5YttxsTyuufuErn/AMdrA8dqoutOcKAzJKCcckApgfqfzNS+ENWEdkbOfAjSVhG/pnDc/ixq5ySppsxc1CWp2FFNV1YsFYEqcMAehxnB/Aj86dUGwUUUUAFRzf6v8R/OpKjm/wBX+I/nQAQ/6v8AE/zqSo4f9X+J/nUlABXP+Lb+906xtprO4MJaby2witkFWPcH0roKgvLe3uLdlubZLhF+YRugfJHoD3pppO7E9jy2+1W51Mot5etMVPyruC8/RcDNRR6fLM5VLKZ2HJJhY4HqSR0967R3uNWvAqrx/Cv8KCuhsrKOyh2Jyx+856saininN+5HQ46cpVZPl27nI+D3bTrq6W6iMSzCNUYkEZG70PuK7es7+xrb7b5+Pk6+VjjP+Ht/+qtGlF1JNuZvRVRJqYUUUVZsFRzf6v8AEfzqSo5v9X+I/nQAQ/6v8T/OpKjh/wBX+J/nUlABRRRQBHHDHE7siKrSHLEDqakoooSsJJLYKKKKBhRRRQAVHN/q/wAR/OpKjm/1f4j+dABD/q/xP86kqGORVTa24EE/wn1p3nJ/tf8AfJoAkoqPzk/2v++TR5yf7X/fJoAkoqPzk/2v++TR5yf7X/fJoAkoqPzk/wBr/vk0ecn+1/3yaAJKKj85P9r/AL5NHnJ/tf8AfJoAkqOb/V/iP50ecn+1/wB8mmySKybV3Ekj+E+tAH//2Q==",
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAGAAAABgCAIAAABt+uBvAAAEvElEQVR4Ae2dTU8TQRjH2XZLw1tbIhSpCfoduHoyfgP0TmLCwRCJJ7+CJw0XDhgSPCrhQGJiosbExJeT3ryi8lKklJS2lEK6tP7rJtvZ2ekuJs5Lw2M4zPPMlH3m1/l1tkMRq9VqnZ2d9dE/EYFkMmmDTj6fHxoaEg241LlarZbL5WysINDJZrOXGoZo8oVCAXBioi7KdQjELMvqRNTyEwCcGFaRP0lRhwAp1mHRrUWKdSPTzpNiYXTQR4pFAEI3KRbGiBQLo4M+UiwCELpJsTBGpFgYHfTpVOyoen7r/tbPvUZEjbq7bawi9TUsvii9+twYGZ96sNQ8Ptx6vzSlvoaLXFGbYhsfqoOZ9gGLFYv1D6YvUquWMdoUi8UT3oSTQ2mTRdOzizXPOy891YOtG5MdXh44ExraFMOLDri4X8a+AOEZgmK2rifKZC4sEz2KsRWY3NammMlQ2Nq07WJsEYa3SbGwJ4gUC6ODPlIsAhC6SbEwRqRYGB30kWIRgNBNioUxgmLtT3eEDfl/fU9W1grFEvv9Hj+aY0MD24Cj6L3Yu49fGy376rXrHoXfu7+8tskNRYrdvjldOjzgQOz7FxTXa0KocxcbHjH3INF7bnTuYsOpzNOVNa8UYxuKFDN2/uGF6VQsvDJDenUqZgiCyDLUKTYxNnpSq0YWZNQApYo9vHf35LjHAKlWzHE6P+3BSrHtxMr2c6OWTLAYdYoFrz02kfvx+nS9uh7sMiSjVDHhnJ2StePsrJZXhb3ak6oV6zbhcrNsLCOdirG8wMhA1zQoFrLTs67hbITFp6sNxax6vV6pVNT8tg/evj97+QbvwtwJO45T3N/lJo+tDS/eSOI8RO+BEX7bJ5VKKfoA1ebW3uZ2HqdCmPlxtexCASn2hIgjZUIIxaScKH759n3j7Sd2hmPZnJ1IGI6DLdhtQzEpJ4q1k1NcoOdwBAEhI2UXw/mh8GL/mtS+r2nYxSIZFffzeHl2T6zZfS3ygTIGyFIsslan0X5TVizkvZF2PD6QTgzfKY17qb8N9x5yNj3rT6uLpO9iuPFpNpvHlSN2TiPTzvB0Y5JJLYwuIFo+Wq636ky63XTvIWdGZri8glDWLobSr2RSriY45cBJkDuZxdKicFYuHXTNZeaEY+Ca8IGyk+puFLEusDqC84n3xedH57k8t46EY7iHyAjdG0UpuxhXbjc6GBakgyTW0YA14H0T4RivV2pD0S4mXDuYmGdWcJJg5CZDxgQf9d8z0nexbmvnItboReOxlqhYNzq4tkZrvJlfpCFXsf6+fmERhiwNYW1cEopJ/L874lacYwGzuAxXkIGhRMXc2bJEesUs73mSq5h3mflM+06HJeV1Gd5Qd6NoOAhheepuFIWX74mkIsV6goWwSLm7mPCSPZeUvov1HBG2YFKMpSFok2ICKFyKFOOA+EJSzIcjGJBiQSZ8hhTjibAxKcbSELRJMQEULkWKcUB8ISnmwxEMSLEgEz5DivFE2JgUY2kI2qSYAAqXIsU4IL6QFPPhCAakWJAJnyHFeCJsTIqxNARtUkwAhUuRYhwQX0iK+XAEA1IsyITPtD8GjL/yg59D8z2XPgaWdDptYRXRn8/qthjw57P+ANN68lp74NRnAAAAAElFTkSuQmCC",
            "text/plain": [
              "<PIL.Image.Image image mode=RGB size=96x96>"
            ]
          },
          "execution_count": 18,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from PIL import Image\n",
        "\n",
        "def render_im(image):\n",
        "    img = (np.clip(image, 0, 1) * 255).astype(np.uint8)\n",
        "    img = img.transpose(1,2,0)\n",
        "    return Image.fromarray(img, mode='RGB')\n",
        "\n",
        "render_im(obs['image'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "class PushTEnvGen(gym.Env):\n",
        "    metadata = {\"render.modes\": [\"human\", \"rgb_array\"], \"video.frames_per_second\": 10}\n",
        "    reward_range = (0.0, 1.0)\n",
        "\n",
        "    def __init__(\n",
        "        self,\n",
        "        seed=0,\n",
        "        legacy=False,\n",
        "        block_cog=None,\n",
        "        damping=None,\n",
        "        render_action=True,\n",
        "        render_size=96,\n",
        "        reset_to_state=None,\n",
        "        max_episode_length=300,\n",
        "        randomize_rotation=False,\n",
        "        scale_low=1.0,\n",
        "        scale_high=1.0,\n",
        "        scale_aspect_limit=100.0,\n",
        "        uniform_scaling=False,\n",
        "        randomize_position=False,\n",
        "        rand_pos_scale=0.0,\n",
        "        term_on_success=True,\n",
        "    ):\n",
        "        print(f\"Creating PushT Env with seed {seed}.\")\n",
        "        self.rng = np.random.RandomState(seed=seed)\n",
        "        self.window_size = ws = 512  # The size of the PyGame window\n",
        "        self.render_size = render_size\n",
        "        self.sim_hz = 100\n",
        "        self.max_episode_length = max_episode_length\n",
        "        # Local controller params.\n",
        "        self.k_p, self.k_v = 100, 20  # PD control.z\n",
        "        self.control_hz = self.metadata[\"video.frames_per_second\"]\n",
        "        # legcay set_state for data compatibility\n",
        "        self.legacy = legacy\n",
        "\n",
        "        self.randomize_rotation = randomize_rotation\n",
        "        self.scale_low, self.scale_high = scale_low, scale_high\n",
        "        self.scale_aspect_limit = scale_aspect_limit\n",
        "        self.uniform_scaling = uniform_scaling\n",
        "        self.randomize_position = randomize_position\n",
        "        self.rand_pos_scale = rand_pos_scale\n",
        "\n",
        "        # agent_pos, block_pos, block_angle\n",
        "        self.observation_space = spaces.Box(\n",
        "            low=np.array([0, 0, 0, 0, 0, 0], dtype=np.float64),\n",
        "            high=np.array([ws, ws, ws, ws, np.pi * 2, np.pi * 2], dtype=np.float64),\n",
        "            shape=(6,),\n",
        "            dtype=np.float64,\n",
        "        )\n",
        "\n",
        "        # positional goal for agent\n",
        "        self.action_space = spaces.Box(\n",
        "            low=np.array([0, 0], dtype=np.float64),\n",
        "            high=np.array([ws, ws], dtype=np.float64),\n",
        "            shape=(2,),\n",
        "            dtype=np.float64,\n",
        "        )\n",
        "\n",
        "        self.block_cog = block_cog\n",
        "        self.damping = damping\n",
        "        self.render_action = render_action\n",
        "        self.term_on_success = term_on_success\n",
        "\n",
        "        \"\"\"\n",
        "        If human-rendering is used, `self.window` will be a reference\n",
        "        to the window that we draw to. `self.clock` will be a clock that is used\n",
        "        to ensure that the environment is rendered at the correct framerate in\n",
        "        human-mode. They will remain `None` until human-mode is used for the\n",
        "        first time.\n",
        "        \"\"\"\n",
        "        self.window = None\n",
        "        self.clock = None\n",
        "        self.screen = None\n",
        "\n",
        "        self.space = None\n",
        "        self.teleop = None\n",
        "        self.render_buffer = None\n",
        "        self.latest_action = None\n",
        "        self.reset_to_state = reset_to_state\n",
        "\n",
        "    @property\n",
        "    def name(self):\n",
        "        return \"pusht\"\n",
        "\n",
        "    def reset(self):\n",
        "        self._t = 0\n",
        "        self._setup()\n",
        "        if self.block_cog is not None:\n",
        "            self.block.center_of_gravity = self.block_cog\n",
        "        if self.damping is not None:\n",
        "            self.space.damping = self.damping\n",
        "\n",
        "        # use legacy RandomState for compatibility\n",
        "        state = self.reset_to_state\n",
        "        if state is None:\n",
        "            rs = self.rng\n",
        "            state = np.array(\n",
        "                [\n",
        "                    rs.randint(50, 450),\n",
        "                    rs.randint(50, 450),\n",
        "                    rs.randint(100, 400),\n",
        "                    rs.randint(100, 400),\n",
        "                    rs.randn() * 2 * np.pi - np.pi,\n",
        "                ]\n",
        "            )\n",
        "        self._set_state(state)\n",
        "\n",
        "        observation = self._get_obs()\n",
        "        info = self._get_info()\n",
        "        return observation, info\n",
        "\n",
        "    def step(self, action, dummy_reward=False):\n",
        "        dt = 1.0 / self.sim_hz\n",
        "        self.n_contact_points = 0\n",
        "        n_steps = self.sim_hz // self.control_hz\n",
        "        if (self.term_on_success and self.compute_reward() == 1.0) or (\n",
        "            self._t + 1\n",
        "        ) >= self.max_episode_length:\n",
        "            # do not take action if done\n",
        "            action = None\n",
        "        if action is not None:\n",
        "            self.latest_action = action\n",
        "            for i in range(n_steps):\n",
        "                # Step PD control.\n",
        "                # self.agent.velocity = self.k_p * (act - self.agent.position)    # P control works too.\n",
        "                acceleration = self.k_p * (action - self.agent.position) + self.k_v * (\n",
        "                    Vec2d(0, 0) - self.agent.velocity\n",
        "                )\n",
        "                self.agent.velocity += acceleration * dt\n",
        "\n",
        "                # Step physics.\n",
        "                self.space.step(dt)\n",
        "\n",
        "        reward = self.compute_reward()\n",
        "        done = (self.term_on_success and reward == 1.0) or (\n",
        "            self._t + 1\n",
        "        ) >= self.max_episode_length\n",
        "        observation = self._get_obs()\n",
        "        info = self._get_info()\n",
        "        self._t += 1\n",
        "\n",
        "        return observation, reward if not dummy_reward else 0.0, done, done, info\n",
        "\n",
        "    def compute_reward(self):\n",
        "        # compute reward\n",
        "        goal_body = self._get_goal_pose_body(self.goal_pose)\n",
        "        goal_geom = pymunk_to_shapely(goal_body, self.block.shapes)\n",
        "        block_geom = pymunk_to_shapely(self.block, self.block.shapes)\n",
        "\n",
        "        intersection_area = goal_geom.intersection(block_geom).area\n",
        "        goal_area = goal_geom.area\n",
        "        coverage = intersection_area / goal_area\n",
        "        reward = np.clip(coverage / self.success_threshold, 0.0, 1.0)\n",
        "        return reward\n",
        "\n",
        "    def render(self, mode):\n",
        "        return self._render_frame(mode)\n",
        "\n",
        "    def teleop_agent(self):\n",
        "        TeleopAgent = collections.namedtuple(\"TeleopAgent\", [\"act\"])\n",
        "\n",
        "        def act(obs):\n",
        "            act = None\n",
        "            mouse_position = pymunk.pygame_util.from_pygame(\n",
        "                Vec2d(*pygame.mouse.get_pos()), self.screen\n",
        "            )\n",
        "            if self.teleop or (mouse_position - self.agent.position).length < 30:\n",
        "                self.teleop = True\n",
        "                act = mouse_position\n",
        "            return act\n",
        "\n",
        "        return TeleopAgent(act)\n",
        "\n",
        "    def _get_obs(self):\n",
        "        obs = np.array(\n",
        "            tuple(self.agent.position)\n",
        "            + tuple(self.block.position)\n",
        "            + (self.block.angle % (2 * np.pi), self.goal_pose[-1])\n",
        "        )\n",
        "        return obs\n",
        "\n",
        "    def _get_goal_pose_body(self, pose):\n",
        "        mass = 1\n",
        "        inertia = pymunk.moment_for_box(mass, (50, 100))\n",
        "        body = pymunk.Body(mass, inertia)\n",
        "        # preserving the legacy assignment order for compatibility\n",
        "        # the order here doesn't matter somehow, maybe because CoM is aligned with body origin\n",
        "        body.position = pose[:2].tolist()\n",
        "        body.angle = pose[2]\n",
        "        return body\n",
        "\n",
        "    def _get_info(self):\n",
        "        n_steps = self.sim_hz // self.control_hz\n",
        "        n_contact_points_per_step = int(np.ceil(self.n_contact_points / n_steps))\n",
        "        info = {\n",
        "            \"pos_agent\": np.array(self.agent.position),\n",
        "            \"vel_agent\": np.array(self.agent.velocity),\n",
        "            \"block_pose\": np.array(list(self.block.position) + [self.block.angle]),\n",
        "            \"goal_pose\": self.goal_pose,\n",
        "            \"n_contacts\": n_contact_points_per_step,\n",
        "        }\n",
        "        return info\n",
        "\n",
        "    def _render_frame(self, mode):\n",
        "\n",
        "        if self.window is None and mode == \"human\":\n",
        "            pygame.init()\n",
        "            pygame.display.init()\n",
        "            self.window = pygame.display.set_mode((self.window_size, self.window_size))\n",
        "        if self.clock is None and mode == \"human\":\n",
        "            self.clock = pygame.time.Clock()\n",
        "\n",
        "        canvas = pygame.Surface((self.window_size, self.window_size))\n",
        "        canvas.fill((255, 255, 255))\n",
        "        self.screen = canvas\n",
        "\n",
        "        draw_options = DrawOptions(canvas)\n",
        "\n",
        "        # Draw goal pose.\n",
        "        goal_body = self._get_goal_pose_body(self.goal_pose)\n",
        "        for shape in self.block.shapes:\n",
        "            goal_points = [\n",
        "                pymunk.pygame_util.to_pygame(\n",
        "                    goal_body.local_to_world(v), draw_options.surface\n",
        "                )\n",
        "                for v in shape.get_vertices()\n",
        "            ]\n",
        "            goal_points += [goal_points[0]]\n",
        "            pygame.draw.polygon(canvas, self.goal_color, goal_points)\n",
        "        # Draw agent and block.\n",
        "        self.space.debug_draw(draw_options)\n",
        "\n",
        "        if mode == \"human\":\n",
        "            # The following line copies our drawings from `canvas` to the visible window\n",
        "            self.window.blit(canvas, canvas.get_rect())\n",
        "            pygame.event.pump()\n",
        "            pygame.display.update()\n",
        "\n",
        "            # the clock is already ticked during in step for \"human\"\n",
        "\n",
        "        img = np.transpose(np.array(pygame.surfarray.pixels3d(canvas)), axes=(1, 0, 2))\n",
        "        img = cv2.resize(img, (self.render_size, self.render_size))\n",
        "        if self.render_action:\n",
        "            if self.render_action and (self.latest_action is not None):\n",
        "                action = np.array(self.latest_action)\n",
        "                coord = (action / 512 * self.render_size).astype(np.int32)\n",
        "                marker_size = int(8 / 96 * self.render_size)\n",
        "                thickness = int(1 / 96 * self.render_size)\n",
        "                cv2.drawMarker(\n",
        "                    img,\n",
        "                    coord,\n",
        "                    color=(255, 0, 0),\n",
        "                    markerType=cv2.MARKER_CROSS,\n",
        "                    markerSize=marker_size,\n",
        "                    thickness=thickness,\n",
        "                )\n",
        "        return img\n",
        "\n",
        "    def close(self):\n",
        "        if self.window is not None:\n",
        "            pygame.display.quit()\n",
        "            pygame.quit()\n",
        "\n",
        "    def _handle_collision(self, arbiter, space, data):\n",
        "        self.n_contact_points += len(arbiter.contact_point_set.points)\n",
        "\n",
        "    def _set_state(self, state):\n",
        "        if isinstance(state, np.ndarray):\n",
        "            state = state.tolist()\n",
        "        pos_agent = state[:2]\n",
        "        pos_block = state[2:4]\n",
        "        rot_block = state[4]\n",
        "        self.agent.position = pos_agent\n",
        "        # setting angle rotates with respect to center of mass\n",
        "        # therefore will modify the geometric position\n",
        "        # if not the same as CoM\n",
        "        # therefore should be modified first.\n",
        "        if self.legacy:\n",
        "            # for compatibility with legacy data\n",
        "            self.block.position = pos_block\n",
        "            self.block.angle = rot_block\n",
        "        else:\n",
        "            self.block.angle = rot_block\n",
        "            self.block.position = pos_block\n",
        "\n",
        "        # Run physics to take effect\n",
        "        self.space.step(1.0 / self.sim_hz)\n",
        "\n",
        "    def _set_state_local(self, state_local):\n",
        "        agent_pos_local = state_local[:2]\n",
        "        block_pose_local = state_local[2:]\n",
        "        tf_img_obj = st.AffineTransform(\n",
        "            translation=self.goal_pose[:2], rotation=self.goal_pose[2]\n",
        "        )\n",
        "        tf_obj_new = st.AffineTransform(\n",
        "            translation=block_pose_local[:2], rotation=block_pose_local[2]\n",
        "        )\n",
        "        tf_img_new = st.AffineTransform(matrix=tf_img_obj.params @ tf_obj_new.params)\n",
        "        agent_pos_new = tf_img_new(agent_pos_local)\n",
        "        new_state = np.array(\n",
        "            list(agent_pos_new[0])\n",
        "            + list(tf_img_new.translation)\n",
        "            + [tf_img_new.rotation]\n",
        "        )\n",
        "        self._set_state(new_state)\n",
        "        return new_state\n",
        "\n",
        "    def _setup(self):\n",
        "        self.space = pymunk.Space()\n",
        "        self.space.gravity = 0, 0\n",
        "        self.space.damping = 0\n",
        "        self.teleop = False\n",
        "        self.render_buffer = list()\n",
        "\n",
        "        # Add walls.\n",
        "        walls = [\n",
        "            self._add_segment((5, 506), (5, 5), 2),\n",
        "            self._add_segment((5, 5), (506, 5), 2),\n",
        "            self._add_segment((506, 5), (506, 506), 2),\n",
        "            self._add_segment((5, 506), (506, 506), 2),\n",
        "        ]\n",
        "        self.space.add(*walls)\n",
        "\n",
        "        # Add agent, block, and goal zone.\n",
        "        self.agent = self.add_circle((256, 400), 15)\n",
        "        if self.scale_low == self.scale_high:\n",
        "            self._length = 4\n",
        "            self._scale = np.array([30.0, 30.0]) * self.scale_low\n",
        "        else:\n",
        "            scale_low, scale_high = self.scale_low, self.scale_high\n",
        "            if self.uniform_scaling:\n",
        "                scale = self.rng.rand() * (scale_high - scale_low) + scale_low\n",
        "                scale = np.array([scale, scale])\n",
        "            else:\n",
        "                scale = self._sample_scale(\n",
        "                    scale_low, scale_high, 2, aspect_limit=self.scale_aspect_limit\n",
        "                )\n",
        "            scale *= 30\n",
        "            self._scale = scale\n",
        "            self._length = 4 * (scale[0] / scale[1])\n",
        "        self.block = self.add_tee(\n",
        "            (256, 300), 0, length=self._length, scale=self._scale[1]\n",
        "        )\n",
        "        self.goal_color = pygame.Color(\"LightGreen\")\n",
        "        if not self.randomize_rotation:\n",
        "            self.goal_pose = np.array([256, 256, np.pi / 4])  # x, y, theta (in radians)\n",
        "        else:\n",
        "            self.goal_pose = np.array([256, 256, np.pi * 2 * self.rng.rand()])\n",
        "        if self.randomize_position:\n",
        "            self.goal_pose[:2] += self.rng.randn(2) * self.rand_pos_scale\n",
        "\n",
        "        # Add collision handling\n",
        "        self.collision_handeler = self.space.add_collision_handler(0, 0)\n",
        "        self.collision_handeler.post_solve = self._handle_collision\n",
        "        self.n_contact_points = 0\n",
        "\n",
        "        self.max_score = 50 * 100\n",
        "        self.success_threshold = 0.95  # 95% coverage.\n",
        "\n",
        "    def _sample_scale(self, low, high, size, aspect_limit=None):\n",
        "        while True:\n",
        "            scale = self.rng.rand(size) * (high - low) + low\n",
        "            if aspect_limit is None or scale.max() / scale.min() < aspect_limit:\n",
        "                break\n",
        "        return scale\n",
        "\n",
        "    def _add_segment(self, a, b, radius):\n",
        "        shape = pymunk.Segment(self.space.static_body, a, b, radius)\n",
        "        shape.color = pygame.Color(\n",
        "            \"LightGray\"\n",
        "        )  # https://htmlcolorcodes.com/color-names\n",
        "        return shape\n",
        "\n",
        "    def add_circle(self, position, radius):\n",
        "        body = pymunk.Body(body_type=pymunk.Body.KINEMATIC)\n",
        "        body.position = position\n",
        "        body.friction = 1\n",
        "        shape = pymunk.Circle(body, radius)\n",
        "        shape.color = pygame.Color(\"RoyalBlue\")\n",
        "        self.space.add(body, shape)\n",
        "        return body\n",
        "\n",
        "    def add_box(self, position, height, width):\n",
        "        mass = 1\n",
        "        inertia = pymunk.moment_for_box(mass, (height, width))\n",
        "        body = pymunk.Body(mass, inertia)\n",
        "        body.position = position\n",
        "        shape = pymunk.Poly.create_box(body, (height, width))\n",
        "        shape.color = pygame.Color(\"LightSlateGray\")\n",
        "        self.space.add(body, shape)\n",
        "        return body\n",
        "\n",
        "    def add_tee(\n",
        "        self,\n",
        "        position,\n",
        "        angle,\n",
        "        length=4,\n",
        "        scale=30,\n",
        "        color=\"LightSlateGray\",\n",
        "        mask=pymunk.ShapeFilter.ALL_MASKS(),\n",
        "    ):\n",
        "        mass = 1\n",
        "        vertices1 = [\n",
        "            (-length * scale / 2, scale),\n",
        "            (length * scale / 2, scale),\n",
        "            (length * scale / 2, 0),\n",
        "            (-length * scale / 2, 0),\n",
        "        ]\n",
        "        inertia1 = pymunk.moment_for_poly(mass, vertices=vertices1)\n",
        "        vertices2 = [\n",
        "            (-scale / 2, scale),\n",
        "            (-scale / 2, length * scale),\n",
        "            (scale / 2, length * scale),\n",
        "            (scale / 2, scale),\n",
        "        ]\n",
        "        inertia2 = pymunk.moment_for_poly(mass, vertices=vertices1)\n",
        "        body = pymunk.Body(mass, inertia1 + inertia2)\n",
        "        shape1 = pymunk.Poly(body, vertices1)\n",
        "        shape2 = pymunk.Poly(body, vertices2)\n",
        "        shape1.color = pygame.Color(color)\n",
        "        shape2.color = pygame.Color(color)\n",
        "        shape1.filter = pymunk.ShapeFilter(mask=mask)\n",
        "        shape2.filter = pymunk.ShapeFilter(mask=mask)\n",
        "        body.center_of_gravity = (\n",
        "            shape1.center_of_gravity + shape2.center_of_gravity\n",
        "        ) / 2\n",
        "        body.position = position\n",
        "        body.angle = angle\n",
        "        body.friction = 1\n",
        "        self.space.add(body, shape1, shape2)\n",
        "        return body\n",
        "\n",
        "class PushTImageEnvGen(PushTEnvGen):\n",
        "    metadata = {\"render.modes\": [\"rgb_array\"], \"video.frames_per_second\": 10}\n",
        "\n",
        "    def __init__(self,\n",
        "                 seed=0,\n",
        "                 legacy=False,\n",
        "                 block_cog=None,\n",
        "                 damping=None,\n",
        "                 render_size=96,\n",
        "                 reset_to_state=None,\n",
        "                 max_episode_length=300,\n",
        "                 randomize_rotation=False,\n",
        "                 scale_low=1.0,\n",
        "                 scale_high=1.0,\n",
        "                 scale_aspect_limit=100.0,\n",
        "                 uniform_scaling=False,\n",
        "                 randomize_position=False,\n",
        "                 rand_pos_scale=0.0,\n",
        "                 term_on_success=True):\n",
        "        # disable the base action‐marker (we’ll draw it ourselves on the image)\n",
        "        super().__init__(\n",
        "            seed=seed,\n",
        "            legacy=legacy,\n",
        "            block_cog=block_cog,\n",
        "            damping=damping,\n",
        "            render_action=False,\n",
        "            render_size=render_size,\n",
        "            reset_to_state=reset_to_state,\n",
        "            max_episode_length=max_episode_length,\n",
        "            randomize_rotation=randomize_rotation,\n",
        "            scale_low=scale_low,\n",
        "            scale_high=scale_high,\n",
        "            scale_aspect_limit=scale_aspect_limit,\n",
        "            uniform_scaling=uniform_scaling,\n",
        "            randomize_position=randomize_position,\n",
        "            rand_pos_scale=rand_pos_scale,\n",
        "            term_on_success=term_on_success\n",
        "        )\n",
        "\n",
        "        ws = self.window_size\n",
        "        self.observation_space = spaces.Dict({\n",
        "            \"image\": spaces.Box(\n",
        "                low=0.0,\n",
        "                high=1.0,\n",
        "                shape=(3, render_size, render_size),\n",
        "                dtype=np.float32\n",
        "            ),\n",
        "            \"agent_pos\": spaces.Box(\n",
        "                low=0.0,\n",
        "                high=ws,\n",
        "                shape=(2,),\n",
        "                dtype=np.float32\n",
        "            )\n",
        "        })\n",
        "\n",
        "        # cache last rendered frame\n",
        "        self.render_cache = None\n",
        "\n",
        "    def _get_obs(self):\n",
        "        # render raw RGB image\n",
        "        img = super()._render_frame(mode=\"rgb_array\")\n",
        "\n",
        "        agent_pos = np.array(self.agent.position)\n",
        "        img_obs = np.moveaxis(img.astype(np.float32) / 255, -1, 0)\n",
        "        obs = {\n",
        "            'image': img_obs,\n",
        "            'agent_pos': agent_pos\n",
        "        }\n",
        "        # optionally overlay the action marker\n",
        "        if self.latest_action is not None:\n",
        "            coord = (np.array(self.latest_action) / self.window_size * self.render_size).astype(int)\n",
        "            marker_size = int(8/96 * self.render_size)\n",
        "            thickness = int(1/96 * self.render_size)\n",
        "            cv2.drawMarker(\n",
        "                img, tuple(coord),\n",
        "                color=(255, 0, 0),\n",
        "                markerType=cv2.MARKER_CROSS,\n",
        "                markerSize=marker_size,\n",
        "                thickness=thickness\n",
        "            )\n",
        "        self.render_cache = img\n",
        "\n",
        "        assert self.render_cache is not None\n",
        "\n",
        "        return obs\n",
        "\n",
        "    def render(self, mode=\"rgb_array\"):\n",
        "        assert mode == \"rgb_array\"\n",
        "        if self.render_cache is None:\n",
        "            # if nobody’s called _get_obs() yet\n",
        "            self._get_obs()\n",
        "        return self.render_cache"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 70,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Creating PushT Env with seed 100000.\n"
          ]
        }
      ],
      "source": [
        "env = PushTImageEnvGen(seed=100000,\n",
        "                 legacy=False,\n",
        "                 block_cog=None,\n",
        "                 damping=None,\n",
        "                 render_size=96,\n",
        "                 reset_to_state=None,\n",
        "                 max_episode_length=300,\n",
        "                 randomize_rotation=False,\n",
        "                 scale_low=1.0,\n",
        "                 scale_high=1.0,\n",
        "                 scale_aspect_limit=100.0,\n",
        "                 uniform_scaling=False,\n",
        "                 randomize_position=False,\n",
        "                 rand_pos_scale=0.0,\n",
        "                 term_on_success=True\n",
        "                 )\n",
        "\n",
        "obs, info = env.reset()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 71,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "image/jpeg": "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",
            "image/png": "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",
            "text/plain": [
              "<PIL.Image.Image image mode=RGB size=96x96>"
            ]
          },
          "execution_count": 71,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "render_im(obs['image'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {},
      "outputs": [],
      "source": [
        "res = env.render(mode='rgb_array')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Example Rollout with General Image Environment"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 73,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Creating PushT Env with seed 100000.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Eval PushTImageEnv:   0%|          | 0/200 [00:00<?, ?it/s]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Eval PushTImageEnv:  72%|███████▏  | 143/200 [00:10<00:04, 13.43it/s, reward=1]     "
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Score:  1.0\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<video controls  width=\"256\"  height=\"256\">\n",
              " <source src=\"data:video/mp4;base64,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\" type=\"video/mp4\">\n",
              " Your browser does not support the video tag.\n",
              " </video>"
            ],
            "text/plain": [
              "<IPython.core.display.Video object>"
            ]
          },
          "execution_count": 73,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "env = PushTImageEnvGen(seed=100000,\n",
        "                 legacy=False,\n",
        "                 block_cog=None,\n",
        "                 damping=None,\n",
        "                 render_size=96,\n",
        "                 reset_to_state=None,\n",
        "                 max_episode_length=200,\n",
        "                 randomize_rotation=False,\n",
        "                 scale_low=1.0,\n",
        "                 scale_high=1.0,\n",
        "                 scale_aspect_limit=100.0,\n",
        "                 uniform_scaling=False,\n",
        "                 randomize_position=False,\n",
        "                 rand_pos_scale=0.0,\n",
        "                 term_on_success=True    \n",
        "                 )\n",
        "\n",
        "# get first observation\n",
        "obs, info = env.reset()\n",
        "\n",
        "# keep a queue of last 2 steps of observations\n",
        "obs_deque = collections.deque(\n",
        "    [obs] * obs_horizon, maxlen=obs_horizon)\n",
        "# save visualization and rewards\n",
        "imgs = [env.render(mode='rgb_array')]\n",
        "rewards = list()\n",
        "done = False\n",
        "step_idx = 0\n",
        "\n",
        "with tqdm(total=max_steps, desc=\"Eval PushTImageEnv\") as pbar:\n",
        "    while not done:\n",
        "        B = 1\n",
        "        # stack the last obs_horizon number of observations\n",
        "        images = np.stack([x['image'] for x in obs_deque])\n",
        "        agent_poses = np.stack([x['agent_pos'] for x in obs_deque])\n",
        "\n",
        "        # normalize observation\n",
        "        nagent_poses = normalize_data(agent_poses, stats=stats['agent_pos'])\n",
        "        # images are already normalized to [0,1]\n",
        "        nimages = images\n",
        "\n",
        "        # device transfer\n",
        "        nimages = torch.from_numpy(nimages).to(device, dtype=torch.float32)\n",
        "        # (2,3,96,96)\n",
        "        nagent_poses = torch.from_numpy(nagent_poses).to(device, dtype=torch.float32)\n",
        "        # (2,2)\n",
        "\n",
        "        # infer action\n",
        "        with torch.no_grad():\n",
        "            # get image features\n",
        "            image_features = ema_nets['vision_encoder'](nimages)\n",
        "            # (2,512)\n",
        "\n",
        "            # concat with low-dim observations\n",
        "            obs_features = torch.cat([image_features, nagent_poses], dim=-1)\n",
        "\n",
        "            # reshape observation to (B,obs_horizon*obs_dim)\n",
        "            obs_cond = obs_features.unsqueeze(0).flatten(start_dim=1)\n",
        "\n",
        "            # initialize action from Guassian noise\n",
        "            noisy_action = torch.randn(\n",
        "                (B, pred_horizon, action_dim), device=device)\n",
        "            naction = noisy_action\n",
        "\n",
        "            # init scheduler\n",
        "            noise_scheduler.set_timesteps(num_diffusion_iters)\n",
        "\n",
        "            for k in noise_scheduler.timesteps:\n",
        "                # predict noise\n",
        "                noise_pred = ema_nets['noise_pred_net'](\n",
        "                    sample=naction,\n",
        "                    timestep=k,\n",
        "                    global_cond=obs_cond\n",
        "                )\n",
        "\n",
        "                # inverse diffusion step (remove noise)\n",
        "                naction = noise_scheduler.step(\n",
        "                    model_output=noise_pred,\n",
        "                    timestep=k,\n",
        "                    sample=naction\n",
        "                ).prev_sample\n",
        "\n",
        "        # unnormalize action\n",
        "        naction = naction.detach().to('cpu').numpy()\n",
        "        # (B, pred_horizon, action_dim)\n",
        "        naction = naction[0]\n",
        "        action_pred = unnormalize_data(naction, stats=stats['action'])\n",
        "\n",
        "        # only take action_horizon number of actions\n",
        "        start = obs_horizon - 1\n",
        "        end = start + action_horizon\n",
        "        action = action_pred[start:end,:]\n",
        "        # (action_horizon, action_dim)\n",
        "\n",
        "        # execute action_horizon number of steps\n",
        "        # without replanning\n",
        "        for i in range(len(action)):\n",
        "            # stepping env\n",
        "            obs, reward, done, _, info = env.step(action[i])\n",
        "            # save observations\n",
        "            obs_deque.append(obs)\n",
        "            # and reward/vis\n",
        "            rewards.append(reward)\n",
        "            imgs.append(env.render(mode='rgb_array'))\n",
        "\n",
        "            # update progress bar\n",
        "            step_idx += 1\n",
        "            pbar.update(1)\n",
        "            pbar.set_postfix(reward=reward)\n",
        "            if step_idx > max_steps:\n",
        "                done = True\n",
        "            if done:\n",
        "                break\n",
        "\n",
        "# print out the maximum target coverage\n",
        "print('Score: ', max(rewards))\n",
        "\n",
        "# visualize\n",
        "from IPython.display import Video\n",
        "vwrite('vis.mp4', imgs)\n",
        "Video('vis.mp4', embed=True, width=256, height=256)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "sentinel",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.13"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "0873a2dee0e44b0fb3e8445d94c27171": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7fd765bcd2a34db49a02839ba1c4f518",
            "placeholder": "​",
            "style": "IPY_MODEL_d9054c34284045eda3546a21bb5fafc3",
            "value": "Epoch:   2%"
          }
        },
        "09152dbe3c8543aa809aa592afdc53f1": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_47b6383ed3b64b7e8c7e66d0e7a468d9",
            "placeholder": "​",
            "style": "IPY_MODEL_1cdde5afac8041bf9b75e0e80bd80630",
            "value": " 2/100 [03:14&lt;2:38:57, 97.32s/it, loss=0.0192]"
          }
        },
        "11d14b9bf0f74bf7bd1b58e6a26fd49e": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "12ef3c026774405cb91faf18d7fd8afa": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_eb23edb22d624aee9fd55ab05e2a517e",
            "placeholder": "​",
            "style": "IPY_MODEL_a073d659b0f347c9b30c343430d7f6aa",
            "value": " 379/379 [01:37&lt;00:00,  4.40it/s, loss=0.0185]"
          }
        },
        "16b5928585984a1b81b809717f125489": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1faac530b70b41a58a8c9c0cf44af69c",
            "placeholder": "​",
            "style": "IPY_MODEL_7cfefcf49a9a426da4e9203ec4debe38",
            "value": " 379/379 [01:37&lt;00:00,  4.57it/s, loss=0.0103]"
          }
        },
        "182afbf676cd4c0982b90890bbdbeeef": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "185ce2207cec4ae1a6ffdecadae23894": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "19e913a07b044b2d91ca7b5d2dbbe8f7": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_11d14b9bf0f74bf7bd1b58e6a26fd49e",
            "placeholder": "​",
            "style": "IPY_MODEL_e9fde27bd58b499bb386b36314d9efca",
            "value": ""
          }
        },
        "1b96a78d8b8542eb830e3c446a0dcf42": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1cdde5afac8041bf9b75e0e80bd80630": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1d0a57ed8e914d31bcc1c36a56451df7": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4cc800669dfd45a784864dd4a3881daa",
            "max": 200,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_95dc6c44f97e4e8882a3657bd2fd66fb",
            "value": 200
          }
        },
        "1de97479fc3e44caae336cf0b1082d02": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5407db80343c44c79350021cd98204f8",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_68e9f5994766480dac5dc77ce043a2e9",
            "value": 0
          }
        },
        "1faac530b70b41a58a8c9c0cf44af69c": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2c31ffecd0494e2a8d0a8cefbea5df8a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5d4a78f691ec4555bf179e5ef5d828ac",
            "placeholder": "​",
            "style": "IPY_MODEL_1b96a78d8b8542eb830e3c446a0dcf42",
            "value": "Eval PushTImageEnv: "
          }
        },
        "333b5148e59e47f3998a5cf5df531baf": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "353cb60a2a73417b81ccbb5e52480ed3": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3c0a27b6addb4c6a977824995548fe90": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3e503eeff5d94f0e9dc8a3d31190c6a2": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "410476fa4ac14dd2b78377f4d779402f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a92fc95c6a3d496997da90c87e24ba01",
            "max": 100,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_9a98272475d940b1b98438c4d02dcc05",
            "value": 2
          }
        },
        "44c486fa8c4241f4a1a245f4e24da769": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3c0a27b6addb4c6a977824995548fe90",
            "max": 379,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_d14f2c65ef9348348250af2df0f32963",
            "value": 379
          }
        },
        "479d2f35498b4fbea77057f3f26fd287": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6c25264289e3411db29f6f8db936b00f",
            "max": 379,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_a0ff8cd1b00544caa12cbd809524dd15",
            "value": 379
          }
        },
        "47b6383ed3b64b7e8c7e66d0e7a468d9": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4abc5a8b257240b99535a6abe5e00ef6": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4cc800669dfd45a784864dd4a3881daa": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5124950790874225b5cca7556f122f9a": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5407db80343c44c79350021cd98204f8": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "54c35b52c4e24543872c8335c935c410": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5c1c61cd14fb4aa8b335684fbf652a29": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_69f323a406004822bf1a0bfd79767c9a",
            "max": 379,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_88a8f5924a1e4a86805e314dd90c17be",
            "value": 11
          }
        },
        "5d4a78f691ec4555bf179e5ef5d828ac": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5f96241543b441fcb13c16d4ca476405": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_e6bbb6ce052045ca895b526c620d8847",
              "IPY_MODEL_5c1c61cd14fb4aa8b335684fbf652a29",
              "IPY_MODEL_a5a2bc5dc0b54a4796e574308bb6c4bc"
            ],
            "layout": "IPY_MODEL_febe66177c604395a78be993eeff7c6d"
          }
        },
        "68e9f5994766480dac5dc77ce043a2e9": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "69f323a406004822bf1a0bfd79767c9a": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6c25264289e3411db29f6f8db936b00f": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6de3445a866442aa9cc7d855cb0d0740": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "70b4b657d68648d9be98c099d061cd5a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_8c0237e38cfd4143aa423dea26637965",
              "IPY_MODEL_44c486fa8c4241f4a1a245f4e24da769",
              "IPY_MODEL_12ef3c026774405cb91faf18d7fd8afa"
            ],
            "layout": "IPY_MODEL_99c0577d549c4dd4a61d9ec0cf6254d5"
          }
        },
        "7508fbad995648a39d2a55953d000786": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_9009dc5a656c4befbf513f2574df5a7d",
              "IPY_MODEL_479d2f35498b4fbea77057f3f26fd287",
              "IPY_MODEL_16b5928585984a1b81b809717f125489"
            ],
            "layout": "IPY_MODEL_9d436c7ee90349a5966f025d095dd0cc"
          }
        },
        "7cfefcf49a9a426da4e9203ec4debe38": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7fd765bcd2a34db49a02839ba1c4f518": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "88a8f5924a1e4a86805e314dd90c17be": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "8c0237e38cfd4143aa423dea26637965": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5124950790874225b5cca7556f122f9a",
            "placeholder": "​",
            "style": "IPY_MODEL_f609505b750747dcaff8a950131743e9",
            "value": "Batch: 100%"
          }
        },
        "9009dc5a656c4befbf513f2574df5a7d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3e503eeff5d94f0e9dc8a3d31190c6a2",
            "placeholder": "​",
            "style": "IPY_MODEL_4abc5a8b257240b99535a6abe5e00ef6",
            "value": "Batch: 100%"
          }
        },
        "95dc6c44f97e4e8882a3657bd2fd66fb": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "99c0577d549c4dd4a61d9ec0cf6254d5": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": "hidden",
            "width": null
          }
        },
        "9a98272475d940b1b98438c4d02dcc05": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "9ada44d21f234712ac5df797c730495a": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9d436c7ee90349a5966f025d095dd0cc": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": "hidden",
            "width": null
          }
        },
        "a073d659b0f347c9b30c343430d7f6aa": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a0ff8cd1b00544caa12cbd809524dd15": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "a5a2bc5dc0b54a4796e574308bb6c4bc": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9ada44d21f234712ac5df797c730495a",
            "placeholder": "​",
            "style": "IPY_MODEL_c777ac64366c40ea8a1f63408879c2ab",
            "value": " 11/379 [00:03&lt;01:34,  3.91it/s, loss=0.0256]"
          }
        },
        "a8e97e26d65147efa2ddb176214e818a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_19e913a07b044b2d91ca7b5d2dbbe8f7",
              "IPY_MODEL_1de97479fc3e44caae336cf0b1082d02",
              "IPY_MODEL_b8d4e152c232416f82f5fb30e2478ef8"
            ],
            "layout": "IPY_MODEL_d66b3f8971b24c81abaefe111e6383a6"
          }
        },
        "a92fc95c6a3d496997da90c87e24ba01": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b0a9f64f47d34769a47e165291d2c550": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_2c31ffecd0494e2a8d0a8cefbea5df8a",
              "IPY_MODEL_1d0a57ed8e914d31bcc1c36a56451df7",
              "IPY_MODEL_e1bb86eb510b47d9ac2311926455bf1f"
            ],
            "layout": "IPY_MODEL_182afbf676cd4c0982b90890bbdbeeef"
          }
        },
        "b34bf5a5d603446fb453bbed31c4469c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_0873a2dee0e44b0fb3e8445d94c27171",
              "IPY_MODEL_410476fa4ac14dd2b78377f4d779402f",
              "IPY_MODEL_09152dbe3c8543aa809aa592afdc53f1"
            ],
            "layout": "IPY_MODEL_e2a91fa6d1514913892c0def2e2ecf78"
          }
        },
        "b8d4e152c232416f82f5fb30e2478ef8": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d00c195ac5644bd0aba81dccf56e2df0",
            "placeholder": "​",
            "style": "IPY_MODEL_54c35b52c4e24543872c8335c935c410",
            "value": " 0/0 [00:00&lt;?, ?it/s]"
          }
        },
        "c777ac64366c40ea8a1f63408879c2ab": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d00c195ac5644bd0aba81dccf56e2df0": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d14f2c65ef9348348250af2df0f32963": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "d66b3f8971b24c81abaefe111e6383a6": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d9054c34284045eda3546a21bb5fafc3": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e1bb86eb510b47d9ac2311926455bf1f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_333b5148e59e47f3998a5cf5df531baf",
            "placeholder": "​",
            "style": "IPY_MODEL_185ce2207cec4ae1a6ffdecadae23894",
            "value": " 201/? [00:34&lt;00:00,  6.11it/s, reward=0.828]"
          }
        },
        "e2a91fa6d1514913892c0def2e2ecf78": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e6bbb6ce052045ca895b526c620d8847": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6de3445a866442aa9cc7d855cb0d0740",
            "placeholder": "​",
            "style": "IPY_MODEL_353cb60a2a73417b81ccbb5e52480ed3",
            "value": "Batch:   3%"
          }
        },
        "e9fde27bd58b499bb386b36314d9efca": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "eb23edb22d624aee9fd55ab05e2a517e": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f609505b750747dcaff8a950131743e9": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "febe66177c604395a78be993eeff7c6d": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
